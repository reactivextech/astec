<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Cloud Computing | IT Svit</title>
	<atom:link href="https://itsvit.com/tag/cloud-computing/feed/" rel="self" type="application/rss+xml" />
	<link>https://itsvit.com</link>
	<description></description>
	<lastBuildDate>Tue, 13 Apr 2021 13:05:16 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.6.10</generator>

<image>
	<url>https://itsvit.com/wp-content/uploads/2019/07/Logo_2-150x150.png</url>
	<title>Cloud Computing | IT Svit</title>
	<link>https://itsvit.com</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>How to Cope with Baffling Cloud Costs</title>
		<link>https://itsvit.com/blog/how-to-cope-with-baffling-cloud-costs/</link>
					<comments>https://itsvit.com/blog/how-to-cope-with-baffling-cloud-costs/#respond</comments>
		
		<dc:creator><![CDATA[Vladimir Fedak]]></dc:creator>
		<pubDate>Tue, 13 Apr 2021 13:05:13 +0000</pubDate>
				<category><![CDATA[Articles]]></category>
		<category><![CDATA[Blog]]></category>
		<category><![CDATA[Cloud Computing]]></category>
		<category><![CDATA[DevOps]]></category>
		<guid isPermaLink="false">https://itsvit.com/?p=8083</guid>

					<description><![CDATA[<p>Over the past couple of years, IT organizations are at full speed migrating their products to the cloud. It’s a noble impulse, considering how beneficial clouds are for the business. What’s the problem then? You might ask. The problem lies in year-to-year growing cloud spending. According to Flexera’s State of Cloud report, 36% of IT [&#8230;]</p>
The post <a href="https://itsvit.com/blog/how-to-cope-with-baffling-cloud-costs/">How to Cope with Baffling Cloud Costs</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></description>
										<content:encoded><![CDATA[<span id="more-8083"></span>
<!--noteaser-->



<p>Over the past couple of years, IT organizations are at full speed migrating their products to the cloud. It’s a noble impulse, considering how beneficial clouds are for the business. What’s the problem then? You might ask. The problem lies in year-to-year growing cloud spending. According to <a href="https://info.flexera.com/CM-REPORT-State-of-the-Cloud">Flexera’s State of Cloud report</a>, 36% of IT business leaders (of 750 responders) said their annual cloud spend exceeded $12 million and 83% claimed that cloud spend goes up to $1.2 million a year. In comparison to last year’s 20% &#8211; over $12 million and 74% &#8211; over $1.2 million this year’s figures show an unfortunate growth. How to migrate to the cloud and build a cost-effective cloud-based infrastructure without extra unseasonable waste will be discussed here.</p>



<h2>Why are businesses so excited about clouds ?</h2>



<p>Why are clouds so popular now? With various cloud computing services providing, such business giants as Amazon (AWS), Microsoft (Azure) and Google (GCP) have taken the lead in the market. Here are main cloud benefits you might be interested in:</p>



<ol><li><b>Effectiveness.</b> Cloud computing services are operated on a global network of reliable data centers, which are constantly upgraded.&nbsp;</li><li><b>Cost.</b> Cloud computing cuts expenses on purchasing hardware/software, configuring/running data centers, getting packs of servers, experts’ support and other services.</li><li><b>Speed.</b> Cloud computing services are designed to provide self-directed service when needed. It means that even a wide range of computing resources can be contributed just in a few minutes.&nbsp;</li><li><b>Security.</b> Cloud providers are focused on providing security and protecting your products, infrastructure and sensitive data with a large scope of policies, technologies, and other commands that strengthen your security stance.</li><li><b>Reliability.</b> Cloud providers enable data backup and disaster recovery for users to be sure that if anything happens their data is mirrored and saved on the provider’s network.</li></ol>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="2375" height="1240" src="https://itsvit.com/wp-content/uploads/2021/04/Why-is-Cloud-Spending-Out-of-Control_.jpg" alt="" class="wp-image-8085" srcset="https://itsvit.com/wp-content/uploads/2021/04/Why-is-Cloud-Spending-Out-of-Control_.jpg 2375w, https://itsvit.com/wp-content/uploads/2021/04/Why-is-Cloud-Spending-Out-of-Control_-768x401.jpg 768w, https://itsvit.com/wp-content/uploads/2021/04/Why-is-Cloud-Spending-Out-of-Control_-1536x802.jpg 1536w, https://itsvit.com/wp-content/uploads/2021/04/Why-is-Cloud-Spending-Out-of-Control_-2048x1069.jpg 2048w" sizes="(max-width: 2375px) 100vw, 2375px" /></figure>



<h2>Why is Cloud Spending Out of Control?</h2>



<p>We just discussed how cost-efficient clouds are. And now we tell you that cloud spending rises. How can it happen? Clouds are supposed to help with money waste, aren’t they?&nbsp; Yes, you’re right, however, FinOps practitioners name gigantic $45 billion in cloud spend annually, uncovering “<em>&#8230;a little secret about the clouds that the bill never goes down</em>” in their recent <a href="https://data.finops.org">report</a>. The survey demonstrated massive sprawl of cloud spend, and a desperate struggle to control and optimize it. We can name a few reasons why companies get into this money trap:&nbsp;</p>



<ul><li><b>Time deficiency. </b>Cloud migration and cloud-based infrastructure building with hard deadlines will likely lead to making mistakes and either grabbing every service possible or skipping important steps. As a result, bills do not go down and businesses don’t get satisfying outcomes.</li><li><b>Experience deficiency.</b> Teams are not experienced enough to complete cloud migration and configure correct cost optimization management.&nbsp;&nbsp;&nbsp;</li><li><b>Skill deficiency.</b> Teams might experience a lack of necessary skills. Especially if we talk about small business and startup teams.&nbsp;</li><li><b>People&#8217;s deficiency.</b> Small teams might not find people to complete such a time and energy-consuming task after all.&nbsp;</li></ul>



<p>Additionally to all mentioned reasons from the organizations’ side of the fence we should name one more very tricky reason why clouds become more and more expensive year by year. The problem is that major cloud providers are often not really clear about cloud pricing. It’s not that they are trying to trick us, no it’s not like that! However, it might be difficult to deal with tangled cloud price mapping for people who are not cloud-gurus. Let’s consider this simple example, your aim is AWS Lambda (cloud functions execution) and you have a web application using the CloudFront CDN. You design such flow &#8212; when a customer interacts with the app it triggers an HTTP request through an API gateway that invokes a Lambda function that takes in the data and stores it in DynamoDB. Easy, right? But not so fast. With this scheme, you will be consuming 4 cloud services. Surprised? Let’s do the math, you’ll need CloudFront CDN to catch the data, API Gateway to route the HTTP requests, Lambda itself to handle the request and finally, DynamoDB for storing. Each of them charging good, you can grab a picture of bills with ugly numbers falling on your head pretty soon. You should think about cloud pricing before you even start considering working with clouds. Only careful planning can save you from unreasonable spending, time and energy wasting.&nbsp;&nbsp;</p>



<h2>How to get cloud costs under control&nbsp;</h2>



<p>IT organization cope with cloud costs and start saving utilizing one of these three ways:</p>



<ol><li><b>Make cloud cost design a part of SDLC (software development lifecycle)</b>. It might seem a bit overwhelming but costs should be part of the SD life-cycle. In this case, taking that cost transparency is very crucial, you will need a strict tagging methodology for every cloud service to be tagged to each microservice that it is consumed by, per environment, per team. Who should know about the spending? It’s good to have a budget holder person but the whole developers and IT operations team should monitor the expenses, which will encourage the right engineering and financial behaviors. Also, we recommend breaking your annual budget into monthly parts that will help teams set their budget goals and reach them. Infrastructure right-sizing and auto-scaling can be done using as many ways and tools as you wish from Github functions-as-a-service to Kubernetes Kube Downscaler. More importantly, is to get that it’s a continual process of assessment and it involves good monitoring around your application and infrastructure.</li><li><b>Use a separate product that will streamline and automate cost data via increasing visibility</b>. To keep teams and budget on track is a very time and energy-consuming process. When manual, it involves most of your and your teams’ resources spent on planning, tagging, right-sizing and, of course, on managing. If you want your team to be involved in the budget management process and you don’t want them to be focusing on money issues only, you should utilize a product to increase the visibility of your spending. With such products as <a href="https://aws.amazon.com/marketplace/pp/B07YL6XHTS">Cloudhealth</a> or <a href="https://aws.amazon.com/marketplace/pp/B087QQR5V3">Cloudwiry</a> in hand, you will be provided with spending insights for each service to help optimize budgeting and prevent extra spending.</li><li><b>Turn to DevOps outsourcing companies</b>. It is a very good idea for SMB and startups because of the lack of skilled professionals experienced enough to include a cloud-cost phase into SDLC, create a product that will streamline and visualize cost data or at least, implement decent cost-optimization automation of your cloud-based infrastructure. We get how overwhelming this whole thing with budget management and teams involved in it might seem. That is why we propose to you one of the easiest and resource-saving ways to take baffling cloud costs under control. If you want to build an effective, cost-efficient cloud-based infrastructure you should consider shaking your hands with mature DevOps teams who will not only provide <a href="https://itsvit.com/services/cloud-computing/">cloud computing</a>, cloud migration, existing cloud infrastructure upgrade or cost-optimization automation services for you but also support your team with the necessary expertise and tech documentation. </li></ol>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="2375" height="1240" src="https://itsvit.com/wp-content/uploads/2021/04/Bottom-line1.jpg" alt="" class="wp-image-8086" srcset="https://itsvit.com/wp-content/uploads/2021/04/Bottom-line1.jpg 2375w, https://itsvit.com/wp-content/uploads/2021/04/Bottom-line1-768x401.jpg 768w, https://itsvit.com/wp-content/uploads/2021/04/Bottom-line1-1536x802.jpg 1536w, https://itsvit.com/wp-content/uploads/2021/04/Bottom-line1-2048x1069.jpg 2048w" sizes="(max-width: 2375px) 100vw, 2375px" /></figure>



<h2>Bottom line&nbsp;</h2>



<p>More than 90% of companies spend more than a million dollars a year on cloud services considering their focus on coping with the problem of unreasonable spending. Lack of time, lack of skilled professionals, lack of experience in cloud operation and, of course, complex pricing map from cloud providers makes selecting services quite confusing. Thus, adding the lack of explicit billing visibility often causes losing control of costs. Frankly speaking, the main problem is that organizations lack responsibility for managing cloud budgets. Budget planning and managing have to become just as much a part of the project lifecycle as development and delivery. We suggest three practical ways how IT businesses can manage budgets and take cloud costs under control: including budget management into SDLC, using a product that provides cost visibility and optimization or turning to mature<a href="https://itsvit.com/services/devops/"> DevOps service</a> companies for them to plan, design and implement cost-efficient cloud-based infrastructure for your team. Plus, a professional DevOps team will provide effective cost-optimization automation of your infrastructure in the cloud for you not to experience money losses in the future.&nbsp;&nbsp;</p>The post <a href="https://itsvit.com/blog/how-to-cope-with-baffling-cloud-costs/">How to Cope with Baffling Cloud Costs</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></content:encoded>
					
					<wfw:commentRss>https://itsvit.com/blog/how-to-cope-with-baffling-cloud-costs/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Bullish DevOps Bulletin &#8212; March 2021</title>
		<link>https://itsvit.com/blog/bullish-devops-bulletin-march-2021/</link>
					<comments>https://itsvit.com/blog/bullish-devops-bulletin-march-2021/#respond</comments>
		
		<dc:creator><![CDATA[Vladimir Fedak]]></dc:creator>
		<pubDate>Tue, 06 Apr 2021 13:02:09 +0000</pubDate>
				<category><![CDATA[Articles]]></category>
		<category><![CDATA[Blog]]></category>
		<category><![CDATA[CI/CD]]></category>
		<category><![CDATA[Cloud Computing]]></category>
		<category><![CDATA[DevOps]]></category>
		<guid isPermaLink="false">https://itsvit.com/?p=8076</guid>

					<description><![CDATA[<p>Bullish DevOps. What does it mean? We see Bullish DevOps as the DevOps that helps your business to grow and, to the contrary, Bearish DevOps is the approach that is not helpful enough, when unprofessionally implemented, and even leads to catastrophic losses. So, we’re sure DevOps at It Svit is Bullish enough at least we [&#8230;]</p>
The post <a href="https://itsvit.com/blog/bullish-devops-bulletin-march-2021/">Bullish DevOps Bulletin — March 2021</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></description>
										<content:encoded><![CDATA[<span id="more-8076"></span>
<!--noteaser-->



<p><b>Bullish DevOps.</b> What does it mean? We see Bullish DevOps as the DevOps that helps your business to grow and, to the contrary, <b>Bearish DevOps </b>is the approach that is not helpful enough, when unprofessionally implemented, and even leads to catastrophic losses. So, we’re sure <a href="https://itsvit.com/services/devops/">DevOps at It Svit</a> is Bullish enough at least we are very bullish on our DevOps! We created a DevOps bulletin for DevOps engineers, ambitious developers and system administrators, IT leaders to catch up on the latest DevOps news and updates including the latest tools and methodologies. Plus helpful guides, tips and recommendations to deal with challenging DevOps projects. Ready to taste the DevOps World’s latest updates and other goodies? Follow us then!&nbsp;</p>



<h2>HashiCorp Consul as a fully managed service for AWS&nbsp;</h2>



<p>In February Hashi Corporation announced that <a href="https://www.hashicorp.com/blog/consul-terraform-sync-beta-release-now-available">HashiCorp Consul </a>now performs as a fully managed service for AWS environments on the HashiCorp Cloud Platform (HCP). HCP Consul is the first fully managed service mesh solution handled and supported by the specialists who created the product. HCP Consul provides a simple service discovery tool easily adopted service mesh for both individuals and businesses while diminishing the operational trouble of launching and running it in production. HCP Consul is designed to help minimize the steps necessary to use Consul within your AWS environments. At a high level, here are the four tasks such as create, deploy, peer and connect that customers need to accomplish to start using HCP Consul. Hashi Corporation also announced the availability of a new<a href="https://www.hashicorp.com/blog/consul-terraform-sync-beta-release-now-available"> HashiCorp Terraform provider for HCP</a>. Terraform tutorials &#8212; <a href="https://www.hashicorp.com/blog/terraform-tutorial-module-creation-recommended-pattern">1</a> &amp; <a href="https://www.hashicorp.com/blog/terraform-tutorial-application-load-balancers-for-blue-green-and-canary-d">2</a>.</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="2375" height="1240" src="https://itsvit.com/wp-content/uploads/2021/04/Guide-for-picking-the-right-Terraform-Security-Code-Analysis-Tool.jpg" alt="" class="wp-image-8077" srcset="https://itsvit.com/wp-content/uploads/2021/04/Guide-for-picking-the-right-Terraform-Security-Code-Analysis-Tool.jpg 2375w, https://itsvit.com/wp-content/uploads/2021/04/Guide-for-picking-the-right-Terraform-Security-Code-Analysis-Tool-768x401.jpg 768w, https://itsvit.com/wp-content/uploads/2021/04/Guide-for-picking-the-right-Terraform-Security-Code-Analysis-Tool-1536x802.jpg 1536w, https://itsvit.com/wp-content/uploads/2021/04/Guide-for-picking-the-right-Terraform-Security-Code-Analysis-Tool-2048x1069.jpg 2048w" sizes="(max-width: 2375px) 100vw, 2375px" /></figure>



<h2>Guide for picking the right Terraform Security Code Analysis Tool</h2>



<p>Have you ever been puzzled by the wide range of choices of static analysis tools for Terraform?&nbsp; Marko Fábry, Cloud Architect and Marek Šottl, Cloud Security Engineer at Revolgy closely looked at the tooling to identify security vulnerabilities and misconfigurations for AWS and GCP. The experts decided to unify different preferences of engineers at Revolgy to provide improved and more consistent secure services to customers. Revolgy engineers started their own testing PoC and evaluated results based on various metrics including false positive and false negative rating, integration options and quality of the recommendations themselves. Revolgy experts in their <a href="https://revolgy.com/blog/complete-guide-for-picking-the-right-tool-for-terraform-security-code-analysis/?utm_source=telegram.me&amp;utm_medium=social&amp;utm_campaign=polnyypo-versii-avtora-gayd-po-vyboru">complete guide for picking the right tool for Terraform Security Code Analysis</a> stressed that there are other tools besides Kubernetes and Ansible aimed at security scanning that are more plug-and-play. At the end of the article, they compare a specific set of such tools.</p>



<h2>Curated Collection of SRE Resources and Examples from first-rate IT organizations</h2>



<p>Need examples of how IT organizations practice SRE (site reliability engineering) around the world? Here is a <a href="https://github.com/upgundecha/howtheysre?utm_source=telegram.me&amp;utm_medium=social&amp;utm_campaign=horoshiy-kuriruemyy-repozitoriy-s-ssylkam">curated collection of publicly available resources on how technology and tech-savvy organizations around the world practice SRE</a>. In 2003 Google had given a task to their software engineers to make their grand scale site more efficient, reliable and user-friendly. The approach Google team used to work with the site turned out to be so effective that many IT giants decided to adopt it. We talk about site reliability engineering practices that are used to implement software development solutions into IT operations processes like performance planning, configuring, monitoring, failure alerting and others. These practices correlate perfectly with DevOps such as continuous integration/delivery and infrastructure as a code approach. Due to SRE, tasks traditionally performed by operation specialists, manually, as a rule, are resolved using automation and software. Automation is the most essential component of the SRE model as site reliability engineers are always searching for ideas on how to improve and automate operations tasks. This way, SRE enhances system’s reliability. In the curated repository of best SRE practices, Github experts collected the most reliable and efficient tools, techniques, books lists from leading IT organizations. However, note please, that repository was created recently, the <a href="https://github.com/upgundecha/howtheysre?utm_source=telegram.me&amp;utm_medium=social&amp;utm_campaign=horoshiy-kuriruemyy-repozitoriy-s-ssylkam">list </a>itself might refer to some of the articles, posts, videos, tools, and techniques published a couple of years ago.</p>



<h2>Kubernetes API Priority and Fairness regulation&nbsp;</h2>



<p>Ivan Slim in his <a href="https://kubernetes.io/docs/concepts/https://itnext.io/kubernetes-api-priority-and-fairness-b1ef2b8a26a2">article about the Kubernetes API Priority and Fairness </a>(<a href="https://kubernetes.io/docs/concepts/cluster-administration/flow-control/">APF</a>) shared what he has discovered and showed how to define policies to prioritize and throttle inbound requests to the Kubernetes API server. Additionally, Ivan went over some metrics and debugging endpoints that can be used to determine if APF is affecting controllers. As a result, he showed how to create custom <em>FlowShema</em> and <em>PirorutyLevelConfiguration </em>resources to regulate inbound traffic to API servers and went over the specifications of these resources.</p>



<h2>Kubernetes NetworkPolicy Editor&nbsp;</h2>



<p>If you want to adopt <a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">Kubernetes NetworkPolicies </a>for apps in your cluster, you should be ready that the learning curve from very basic examples to more complex real-world policies is steep. Even experienced Kubernetes YAML-experts can still easily make their brain explode working through an advanced network policy use case. In the<a href="https://www.cncf.io/webinars/this-week-in-cloud-native-demystifying-kubernetes-network-policy/"> Livestream from Cloud Native Computing Foundation</a>, Thomas Graf went over everything from the basics of Kubernetes Network Policy to more advanced concepts. He explained step by step from setting up simple policies to tackling trickier questions such as spotting and avoiding conflicting rules, looking at common mistakes, and examining some advanced real-world policy examples similar to those implemented by major Kubernetes users. What’s more, CNI Cilium experts created the <a href="https://editor.cilium.io">NetworkPolicy Editor </a>project, which allows you to create, visualize and share network policies online.&nbsp;</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="2375" height="1240" src="https://itsvit.com/wp-content/uploads/2021/04/IAM-Access-Analyzer-Policy-Validation-Update.jpg" alt="" class="wp-image-8078" srcset="https://itsvit.com/wp-content/uploads/2021/04/IAM-Access-Analyzer-Policy-Validation-Update.jpg 2375w, https://itsvit.com/wp-content/uploads/2021/04/IAM-Access-Analyzer-Policy-Validation-Update-768x401.jpg 768w, https://itsvit.com/wp-content/uploads/2021/04/IAM-Access-Analyzer-Policy-Validation-Update-1536x802.jpg 1536w, https://itsvit.com/wp-content/uploads/2021/04/IAM-Access-Analyzer-Policy-Validation-Update-2048x1069.jpg 2048w" sizes="(max-width: 2375px) 100vw, 2375px" /></figure>



<h2>IAM Access Analyzer Policy Validation Update</h2>



<p>A couple of weeks ago, AWS announced the release of the policy validation<a href="https://aws.amazon.com/ru/blogs/aws/iam-access-analyzer-update-policy-validation/"> add-on for the IAM Access Analyzer</a> &#8212; a tool allowing to validate IAM policy configurations for security compliance (over 100 tests based on AWS IAM best practices) and detailed recommendations for configuring IAM. You can use it directly from the IAM Console web interface when creating IAM policies, and the same CLI/API AWS access analyzer validate-policy for integration with custom CI/CD workflows, without the need for third-party tools. From a security point of view, this is a very useful and on-demand functionality that is designed to at least partially solve the problem of misconfigs when configuring IAM policies.</p>



<h2>DevOps roadmap&nbsp;</h2>



<p>Dreaming about a DevOps engineer’s role in a high-class company? DevOps experts of the DevOps Journey community prepared a quite helpful video informing entry-level DevOps specialists or developers/sysadmins wishing to switch to DevOps of the <a href="https://www.youtube.com/watch?v=5pxbp6FyTfk">DevOps roadmap</a> relevant in 2021. <a href="https://itsvit.com/blog/devops-resume-2021-and-interview-questions-get-ready/">DevOps engineers</a> are supposed to work with developing and IT operations teams, QA specialists and production teams to supervise the code delivery and release. DevOps engineers are supposed to have and utilize well-developed soft and hard skills to break the time-honored wall between software production teams and impeccably manage IT infrastructure. Moreover, DevOps engineers should be endowed with leadership and business skills to work with the teams. If you desire to become one, you have to accept the fact that your way to success will not be a piece of cake, just remember IT Svit is here to help you at any stage of your path.&nbsp;</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="2375" height="1240" src="https://itsvit.com/wp-content/uploads/2021/04/Wrapping-things-up.jpg" alt="" class="wp-image-8079" srcset="https://itsvit.com/wp-content/uploads/2021/04/Wrapping-things-up.jpg 2375w, https://itsvit.com/wp-content/uploads/2021/04/Wrapping-things-up-768x401.jpg 768w, https://itsvit.com/wp-content/uploads/2021/04/Wrapping-things-up-1536x802.jpg 1536w, https://itsvit.com/wp-content/uploads/2021/04/Wrapping-things-up-2048x1069.jpg 2048w" sizes="(max-width: 2375px) 100vw, 2375px" /></figure>



<h2>Wrapping things up</h2>



<p>Would you like to get such a bulletin regularly? We hope you’re nodding at least! Well, tell us in the comments what was good to learn and what you want to hear in the next piece. Bullish DevOps Bulletin &#8212; April 2021 is coming up!&nbsp;</p>The post <a href="https://itsvit.com/blog/bullish-devops-bulletin-march-2021/">Bullish DevOps Bulletin — March 2021</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></content:encoded>
					
					<wfw:commentRss>https://itsvit.com/blog/bullish-devops-bulletin-march-2021/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Cloud+DevOps=Faster Delivery &#038; Lower Costs</title>
		<link>https://itsvit.com/blog/clouddevopsfaster-delivery-lower-costs/</link>
					<comments>https://itsvit.com/blog/clouddevopsfaster-delivery-lower-costs/#respond</comments>
		
		<dc:creator><![CDATA[Vladimir Fedak]]></dc:creator>
		<pubDate>Tue, 16 Mar 2021 14:36:29 +0000</pubDate>
				<category><![CDATA[Articles]]></category>
		<category><![CDATA[Blog]]></category>
		<category><![CDATA[Cloud Computing]]></category>
		<category><![CDATA[DevOps]]></category>
		<guid isPermaLink="false">https://itsvit.com/?p=8055</guid>

					<description><![CDATA[<p>Each IT business aims to deliver high-quality, customer-focused software as fast as possible without waste. And while many companies go after innovative and effective methods like DevOps or cloud computing to reach this goal, we stress that the true win here is if we combine these two improvements together. Freedom Dynamics experts identified that utilizing [&#8230;]</p>
The post <a href="https://itsvit.com/blog/clouddevopsfaster-delivery-lower-costs/">Cloud+DevOps=Faster Delivery & Lower Costs</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></description>
										<content:encoded><![CDATA[<span id="more-8055"></span>
<!--noteaser-->



<p>Each IT business aims to deliver high-quality, customer-focused software as fast as possible without waste. And while many companies go after innovative and effective methods like DevOps or cloud computing to reach this goal, we stress that the true win here is if we combine these two improvements together. <a href="https://docs.broadcom.com/doc/devops-cloud-computing-exploiting-synergy-business-advantage">Freedom Dynamics</a> experts identified that utilizing DevOps practices and cloud resources, implemented separately, stimulate software delivery by an impressive 50%. Can you imagine what growth we might have from merging DevOps and cloud? We can tell you &#8212; the software delivery will be accelerated by a whopping 81%. Read on to dive deep into the strategy and learn how to reach those results.&nbsp;</p>



<h2>How using the Cloud accelerates software delivery and cuts costs</h2>



<p>Pandemic 2020 considerably transformed businesses, however, even before the virus outburst, IT organizations had been looking for the ability to transit their key computing facilities to a more agile environment and have larger infrastructure capacity. According to a <a href="https://www.pwc.com/us/en/library/covid-19/pwc-covid-19-cfo-pulse-survey.html">PwC</a> report, 75% of IT decision-makers are considering turning to the cloud’s adjustable and scalable services. With cloud based services you can access computing powers for any scale at an instant via Virtual Machines. Not to mention a huge range of services like networking, analytics and data storage. Here are the top benefits businesses get from using the cloud:</p>



<ul><li><b>Redundancy. </b>Apart from obvious advantages like lower operational costs or increased velocity we want to bring redundancy into focus. Because faster software delivery is great, but what if a system fails, if there is a massive breach or a large-scale downtime, the consequences might be catastrophic for the company. That is why such redundancy benefits as automatic data backups and up-time guaranteed by service level agreement (SLA) are the main assets to consider when moving to the cloud. </li><li><b>Global reach.</b> Digital product owners are able to provide seamless experience for their customers no matter their location. You have R&amp;D in the US but want to target customers in Dubai. Content Delivery Network (CDN) gets you covered. Simply put, if you use the cloud, you can deploy your apps in various countries and regions of the world. </li><li><b>Lower costs.</b> <a href="https://itsvit.com/services/cloud-computing/">Cloud computing </a>cuts expenses on purchasing hardware/software, configuring/running data centers, getting packs of servers, experts’ support and other services. However, here we’d like to stress that clouds do help cut expenses under the condition that you provide correct <a href="https://itsvit.com/blog/cloud-migration-strategy-you-better-have-one/">cloud migration</a> and, additionally, automate cost-optimization management.  </li><li><b>Velocity and fast deployment.</b> Cloud computing services are designed to provide self-directed service when needed. It means that even a wide range of computing resources can be distributed  just in a few minutes, granting organizations access to various computing services with just a couple of mouse clicks or in a few screen-touching operations.</li></ul>



<p>Other critical cloud advantages like on-demand service, pay-as-you-go capacity, effective visualization, all should be considered and greatly valued when you’re planning a cloud migration. </p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="2375" height="1240" src="https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-You-better-have-one-1.jpg" alt="" class="wp-image-8059" srcset="https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-You-better-have-one-1.jpg 2375w, https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-You-better-have-one-1-768x401.jpg 768w, https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-You-better-have-one-1-1536x802.jpg 1536w, https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-You-better-have-one-1-2048x1069.jpg 2048w" sizes="(max-width: 2375px) 100vw, 2375px" /></figure>



<h2>How using DevOps accelerates software delivery and cuts costs</h2>



<p>Today’s digital world is all about delivering high-performing products as quickly as possible, and all businesses work hard on improving processes of software production embracing innovative tools, technology and approaches to meet (hopefully exceed) rising customer expectations. This is where DevOps steps in and accelerates high-quality product delivery improving collaboration between key software development teams. The Internet gives plenty of DevOps definitions, as such we decided to explain how we see DevOps. DevOps — is an approach or a combination of practices and principles that promote and reinforce agile software delivery methodology. With DevOps, teams become more productive, allowing businesses to produce more, improve quality and save money. According to the<a href="https://services.google.com/fh/files/misc/state-of-devops-2019.pdf"> State of DevOps Report</a>, companies that use DevOps hit their profitability and customer satisfaction targets. Here are the main benefits of DevOps:</p>



<ul><li><b>Fast software delivery</b>. With the right DevOps methods, companies deliver new high-quality and customer-focused products/features fast.</li><li><b>Process automation. </b>With DevOps, processes are fully automated that reduce toil and failure rates. Like deployment automation.</li><li><b>Effective collaboration.</b> The software development process is more transparent with DevOps allowing teams to effectively collaborate which significantly improves their productivity.</li></ul>



<p>DevOps, obviously, can be beneficial enough, when implemented correctly. Some companies choose to create an in-house DevOps team, however, pretty often, they turn to mature DevOps companies that provide DevOps services. For most companies, especially small businesses or startups, it’s quite overwhelming to grow an in-house DevOps team, if that’s your case, you should shake your hands with <a href="https://itsvit.com/services/devops/">DevOps services</a> providers.&nbsp;</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="2375" height="1240" src="https://itsvit.com/wp-content/uploads/2021/03/How-do-you-merge-cloud-and-DevOps_.jpg" alt="" class="wp-image-8058" srcset="https://itsvit.com/wp-content/uploads/2021/03/How-do-you-merge-cloud-and-DevOps_.jpg 2375w, https://itsvit.com/wp-content/uploads/2021/03/How-do-you-merge-cloud-and-DevOps_-768x401.jpg 768w, https://itsvit.com/wp-content/uploads/2021/03/How-do-you-merge-cloud-and-DevOps_-1536x802.jpg 1536w, https://itsvit.com/wp-content/uploads/2021/03/How-do-you-merge-cloud-and-DevOps_-2048x1069.jpg 2048w" sizes="(max-width: 2375px) 100vw, 2375px" /></figure>



<h2>How Cloud + DevOps further accelerates software delivery and cuts costs</h2>



<p>With software transported to the cloud, the core infrastructure is significantly modernized with the help of innovative cloud services. DevOps practices can be used to plan and implement a cloud migration correctly and to automate cloud cost-optimization management for companies to avoid unreasonable spending. Moreover, the cloud postmigration on-demand scalability and pay-as-you-go approach can notably accelerate and facilitate software delivery and deployment while significantly reducing costs. <b>Cloud &amp; DevOps combined: &nbsp; </b>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>



<ul><li><b>Improve operability. </b>Cloud adoption together with DevOps principles and practices implementation considerably improves operability, which is specifically critical for startups. Mature companies of all sizes with cloud adoption and DevOps approach implementation can remodel their existing core systems to improve operability.</li><li><b>Optimize expenses.</b> With cloud adoption, many companies claim rapid cloud spending growth. DevOps can solve this very painful problem by automating the key parts of cloud services provisioning and cloud cost-optimization management.</li><li><b>Enhance customer satisfaction.</b> DevOps and cloud together cater for improvements that clear more time and vigor for innovation and constant quality increasing that definitely boosts customer satisfaction.</li></ul>



<h2>How do you merge Cloud and DevOps?</h2>



<p>When you’re just planning cloud adoption and migration, DevOps can be enclosed from the beginning. However, existing infrastructure can also be evolved with DevOps correct implementation. Originally, it involves replatforming, revising, reconstructing, remodeling and renovating the infrastructure without having to perform an exhaustive re-architecting. For many IT businesses, this is the fastest and most distinct way to reach performance improvements in the cloud. Various DevOps approaches and methods can set up cloud environments or evolve existing infrastructures to make the most out of cloud services without unreasonable expenses. In this context, it is critical to mention that Cloud-DevOps improvements have to be carried out correctly by professionals. And in many cases companies, especially SMBs that do not have capacity to build skilled in-house DevOps teams, turn to mature DevOps companies that can provide DevOps services and Cloud consulting. DevOps professionals not only plan, implement and automate cost-optimization management for your cloud migration or redesign and evolve your existing infrastructure but also support your teams with necessary tech documentation.&nbsp;</p>



<h2>Final thoughts: Are Cloud and DevOps better together?</h2>



<p>Despite the fact that cloud and DevOps are good enough used separately, you should consider combining these two improvements because together they make up a killing mixture to streamline your flows, accelerate software delivery, increase software quality, enhance customer satisfaction, optimize and lower costs. With that, if you ask us: “<em>Are Cloud and DevOps better together?</em>” The answer will be absolutely positive. What’s more, we strongly recommend combining these two for your business to win the most.&nbsp;</p>The post <a href="https://itsvit.com/blog/clouddevopsfaster-delivery-lower-costs/">Cloud+DevOps=Faster Delivery & Lower Costs</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></content:encoded>
					
					<wfw:commentRss>https://itsvit.com/blog/clouddevopsfaster-delivery-lower-costs/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Cloud migration strategy. You better have one!</title>
		<link>https://itsvit.com/blog/cloud-migration-strategy-you-better-have-one/</link>
					<comments>https://itsvit.com/blog/cloud-migration-strategy-you-better-have-one/#respond</comments>
		
		<dc:creator><![CDATA[Vladimir Fedak]]></dc:creator>
		<pubDate>Wed, 10 Mar 2021 15:14:02 +0000</pubDate>
				<category><![CDATA[Articles]]></category>
		<category><![CDATA[Blog]]></category>
		<category><![CDATA[Cloud Computing]]></category>
		<category><![CDATA[DevOps]]></category>
		<guid isPermaLink="false">https://itsvit.com/?p=8047</guid>

					<description><![CDATA[<p>Businesses are increasingly migrating their infrastructures into the cloud. The main reason for this to happen is that, with cloud adoption, companies can deliver software faster, reliably and safely without having persistent headaches worrying about the costs and infrastructure operating. Well, in a perfect world at least, but quite sensitive issues hamper IT enterprises, especially [&#8230;]</p>
The post <a href="https://itsvit.com/blog/cloud-migration-strategy-you-better-have-one/">Cloud migration strategy. You better have one!</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></description>
										<content:encoded><![CDATA[<span id="more-8047"></span>
<!--noteaser-->



<p>Businesses are increasingly migrating their infrastructures into the cloud. The main reason for this to happen is that, with cloud adoption, companies can deliver software faster, reliably and safely without having persistent headaches worrying about the costs and infrastructure operating. Well, in a perfect world at least, but quite sensitive issues hamper IT enterprises, especially startups and small businesses to implement cloud migration correctly. And, as a result, instead of coveted cost-effectiveness and better performance, organizations get into money traps and face quality deterioration. Unfortunately, they realize that after the cloud transition is complete. With that, we decided to talk about cloud adoption and migration strategy and how to ensure cost-effective management in the cloud. </p>



<h2>Why are clouds popular?</h2>



<p><a href="https://itsvit.com/services/cloud-computing/">Cloud computing</a> is all about providing computing services, such as servers, networking, analytics, software and storage over the cloud, aka the Internet. Here are the top reasons why businesses are adopting cloud computing that eagerly. </p>



<ul><li><b>Cost.</b> Cloud computing cuts expenses on purchasing hardware/software, configuring/running data centers, getting packs of servers, experts’ support and other services.</li><li><b>Efficiency.</b> Cloud computing services are operated on a global network of reliable data centers, which are constantly upgraded to the latest generation of fast and efficient computing technologies.&nbsp;</li><li><b>Velocity.</b> Cloud computing services are designed to provide self-directed service when needed. It means that even a wide range of computing resources can be contributed just in a few minutes, granting organizations access to various computing services with just a couple of mouse clicks or in a few screen-touching operations.&nbsp;</li><li><b>Protection.</b> Cloud providers are focused on providing security and protecting your products, infrastructure and sensitive data with a large scope of policies, technologies, and other commands that strengthen your security stance.</li><li><b>Reliability.</b> Cloud providers enable data backup and disaster recovery for users to be sure that if anything happens their data is mirrored and saved on the provider’s network.</li></ul>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="2375" height="1240" src="https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-Why-is-cloud-spending-rising-in-2021_.jpg" alt="" class="wp-image-8051" srcset="https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-Why-is-cloud-spending-rising-in-2021_.jpg 2375w, https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-Why-is-cloud-spending-rising-in-2021_-768x401.jpg 768w, https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-Why-is-cloud-spending-rising-in-2021_-1536x802.jpg 1536w, https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-Why-is-cloud-spending-rising-in-2021_-2048x1069.jpg 2048w" sizes="(max-width: 2375px) 100vw, 2375px" /></figure>



<h2>Why is cloud spending rising in 2021?</h2>



<p>Does cloud spending rise? Nonsense! Clouds are supposed to lower the expenses, right? It’s true, but, ironically, according to a recent <a href="https://data.finops.org">report</a>, FinOps practitioners name gigantic $45 billion in cloud spend annually, uncovering “<em>&#8230;a little secret about the clouds that the bill never goes down</em>” claims FinOps Foundation executive director. The survey demonstrated massive sprawl of cloud spend, and a desperate struggle to control and optimize it. Whooping 49%, almost half, of the businesses didn’t have automation of managing cloud spend at all. This fact clarifies that these companies might miss their chance to optimize cloud spend and unreasonably waste their money. What are the reasons for this to happen? We can name a few:&nbsp;</p>



<ul><li><b>Lack of time </b>or moving too fast without a plan. Cloud migration with hard deadlines will likely lead to making mistakes and either grabbing every service possible or skipping important steps. As a result, bills do not go down and businesses don’t get satisfying outcomes.</li><li><b>Lack of experience.</b> Teams are not experienced enough to complete cloud migration and configure correct cost optimization management.   </li><li><b>Lack of skills.</b> Teams might experience a lack of necessary skills.</li><li><b>Lack of people.</b> Small teams might not find people to complete such a time and energy-consuming task after all. </li></ul>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="2375" height="1240" src="https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-What-can-be-done-to-optimize-cloud-costs_.jpg" alt="" class="wp-image-8050" srcset="https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-What-can-be-done-to-optimize-cloud-costs_.jpg 2375w, https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-What-can-be-done-to-optimize-cloud-costs_-768x401.jpg 768w, https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-What-can-be-done-to-optimize-cloud-costs_-1536x802.jpg 1536w, https://itsvit.com/wp-content/uploads/2021/03/Cloud-migration-strategy.-What-can-be-done-to-optimize-cloud-costs_-2048x1069.jpg 2048w" sizes="(max-width: 2375px) 100vw, 2375px" /></figure>



<h2>What can be done to optimize cloud costs?</h2>



<p><b>Make a migration plan and automate cost management! </b>Cloud migration should be planned, so creating a migration plan is the first step. It’s hard, especially for startups, to find the time, but try to dedicate it to planning. And do not forget to create a post-migration plan with the automation of cost-optimization.</p>



<p>One more problem is that teams are not experienced enough when dealing with migration. Lack of expertise in this area gets organizations, especially small businesses, into unreasonable cost spend. In this case, turning to professionals in this field, companies that use best DevOps practices to design and implement the transition plan is the best and the only option. Sometimes we have a different situation. Some companies try to save money and skip essential steps in cloud infrastructure configuring. This leads to unpleasant consequences when instead of saving up they pay twice as much to start over again and set up everything correctly this time.&nbsp;</p>



<p>Small teams might not handle the mission of cloud adoption and migration as it is pretty overwhelming for them. When leaders allocate this kind of task to inexperienced small teams they should be ready to waste a lot of time and money on numerous attempts, not always successful, unreasonable spending, dealing with hidden costs and many other problems. With that, addressing mature DevOps companies is also the best option you have. Moreover, DevOps specialists will consult your team and support you with all necessary documentation.&nbsp;</p>



<p>When you automate vital parts of services, application deployment and orchestration you only use and, logically pay, for the volume you need when you need it. This approach will reduce unreasonable spending and keep the total cost under control. Pretty often teams face troubles with this task as well. One way or another, most organizations either have little or no automation of managing cloud spend. A great idea is to address DevOps professionals for them not only to design and implement cloud migration but also to automate cost-effective management in the cloud. Pretty often companies try to configure a cost estimate that fits their unique business with the help of <a href="https://calculator.aws/#/">AWS pricing calculator</a>, however, some users claim it’s too complex and you need time to master it, so the recommendation here would also be getting professionals to deal with cloud infrastructure designing, configuring and cost optimization.&nbsp;</p>



<h2>Wrapping things up</h2>



<p>Cloud adoption and migration require specialist attention because instead of cost-efficient cloud infrastructure you might get a ‘sticker shock’ dealing with growing cloud bills. However, we strongly believe that good DevOps practice helps to develop effective and low-cost cloud migration and management strategy for all organizations, especially for small businesses and startups. Nobody wants to get stuck in a loop of inexplicable, impulsive or illogical cloud spend. So while you are only thinking of cloud adopting and migrating or dreaming about improving existing cloud infrastructure you do need an enthusiastic focus on cloud cost management. When you integrate <a href="https://itsvit.com/services/devops/">DevOps </a>with your cloud strategy, you’ll keep an eye on cloud costs.</p>The post <a href="https://itsvit.com/blog/cloud-migration-strategy-you-better-have-one/">Cloud migration strategy. You better have one!</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></content:encoded>
					
					<wfw:commentRss>https://itsvit.com/blog/cloud-migration-strategy-you-better-have-one/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>What is Google Cloud best used for? GCP machine types and services</title>
		<link>https://itsvit.com/blog/what-is-google-cloud-best-used-for-gcp-machine-types-and-services/</link>
					<comments>https://itsvit.com/blog/what-is-google-cloud-best-used-for-gcp-machine-types-and-services/#respond</comments>
		
		<dc:creator><![CDATA[Vladimir Fedak]]></dc:creator>
		<pubDate>Wed, 30 Sep 2020 06:10:00 +0000</pubDate>
				<category><![CDATA[Articles]]></category>
		<category><![CDATA[Blog]]></category>
		<category><![CDATA[Cloud Computing]]></category>
		<guid isPermaLink="false">https://itsvit.com/?p=7838</guid>

					<description><![CDATA[<p>Many businesses have to go online in 2020 and they want to know what is Google Cloud capable of? Let’s take a look at GCP machine types and services In the time of global crisis cost-efficiency of resource allocation becomes paramount. Google Cloud Platform is one of the best choices when it comes to cost-efficiency [&#8230;]</p>
The post <a href="https://itsvit.com/blog/what-is-google-cloud-best-used-for-gcp-machine-types-and-services/">What is Google Cloud best used for? GCP machine types and services</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></description>
										<content:encoded><![CDATA[<p>Many businesses have to go online in 2020 and they want to know what is Google Cloud capable of? Let’s take a look at GCP machine types and services</p>



<span id="more-7838"></span>



<p>In the time of global crisis cost-efficiency of resource allocation becomes paramount. Google Cloud Platform is one of the best choices when it comes to cost-efficiency of <a href="https://itsvit.com/services/cloud-computing/">cloud computing</a> operations and it provides a wide range of virtual machines for all types of tasks — from long-term data storage to batch processing, running apps or performing CPU-intensive jobs. Let’s take a closer look at what is <a href="https://itsvit.com/services/cloud-computing/google-cloud-services/">Google Cloud</a> best used for and list GCP machine types along with the tasks they can perform.</p>



<h2>What is Google Cloud good at? Everything!</h2>



<p>First of all, what is Google Cloud composed of and what is it best used for, in terms of virtual machines? This clarification is essential, as covering Google Cloud in its entirety would require effectively doubling millions of characters of their in-depth help documentation. GCP provides cloud application hosting and data storage, monitoring and security services, <a href="https://itsvit.com/services/big-data/">Big Data</a> processing and CI/CD pipeline configuration for software development and infrastructure management, serverless computing and distributed database management — and the list can go on and on&#8230; </p>



<p>However, based on IT Svit experience, most customers go to Google Cloud to solve some specific business challenges. They want to increase the performance of their databases, secure their mission-critical assets, enable rapid development of features for their products, etc. In general, Google Cloud has more than a hundred services, tools, platforms and products able to solve literally any business challenge and help companies big and small reach their objectives. All of this grew from humble over a decade of providing the capabilities of world-class infrastructure behind Google Search Engine and Google Drive Suite to everybody, for free.</p>



<ol><li><b>Google Cloud provides top-notch security</b>. This is proven by more than 8 various industry-wide certifications, and GCP has won Gartner’s “World’s best cloud security” title for many years. Companies like Pizza Hut, PayPal, Home Depot, Target and HSBS have selected Google Cloud as their technology provider — and these enterprise mammoths take their cybersecurity quite seriously.</li><li><b>Hybrid cloud and multi-cloud strategy</b>. Many enterprises have invested decades and billions of dollars in building their legacy software delivery and data management. These companies come from retail, telecom, finances, healthcare and a variety of other industries — and they usually are industry-leaders in their respective domains.<br>20th Century Fox, eBay, L.L.Bean, Bloomberg, Colgate-Palmolive and other global leaders use Google Cloud to improve their customer experience by providing better software delivery workflows and infrastructure management processes, Big Data processing, etc. This allows them to build software delivery and infrastructure management pipelines that work equally well in the hybrid cloud and multi-cloud scenarios — so they can build it once with Google and use it anywhere they like.</li><li><b>The flexibility of operations</b>. Google Cloud enables a wide variety of service models — from IaaS to PaaS and SaaS as well as serverless computing with Google Functions. This helps build automated processes, save money at scale and provide transformative experiences both to businesses and to their customers. Metro and Nielsen, LG and LATAM Airlines work with Google Cloud to optimize their IT operations, data processing and software development and bring more value to their customers.</li><li><b>Artificial Intelligence and Big Data Analytics</b>. Trained and empowered by intense Google Translator and Google Search Engine usage, AI/ML models and <a href="https://itsvit.com/services/big-data/big-data-analytics/">Big Data analytics</a> processes from Google Cloud are world-leading instruments that can help any company turn its Big Data into a goldmine of useful business insights. The New York Times, SKY U.K., Target and McKesson use Google to imbue their IT systems with the latest achievements of AI development and reap the benefits of Big Data analytics at scale.</li><li><b>Endless innovation</b>. Google is one of the technology leaders worldwide, developing a wide variety of projects that change our lives daily and Google Cloud is where these innovative solutions are first deployed — so Google Cloud users are the ones that can benefit from them at once. There are more than 40 pages of Google Cloud customers covering 300+ world-leading companies in total, so they and more than 5 million startups, SMBs and individual users get instant access to the latest technological wonders from Google.</li><li><b>Per-second billing and other discounts</b>. This is one of the most compelling benefits of GCP. Depending on the type of services you use and the term of usage, you can save up to 90% as compared to AWS or Azure due to leveraging various cost-saving options. Per-second billing, long-term discounts, preemptible VM instances and other ways of cutting on expenses help more than 5 million users remain competitive and cost-efficient in the time of crisis.</li></ol>



<p>As you can see, Google Cloud can cover any request your business or organization might have and provide reliable multi-faceted services. However, how to select the most appropriate infrastructure components for your Google Cloud systems?</p>



<h2>GCP machine types and what to use them for</h2>



<p>Google Cloud delivers Infrastructure-as-a-Service by the means of its Google Compute Engine. GCE is an interface to the entirety of hardware resources currently deployed by Google, allowing the customers to use this hardware and networking assets. Google Compute Engine VMs <b>boot in under 30 seconds</b>, which is 4-10x times faster than the similar offers from competitors.</p>



<p>Compute engine uses <b>KVM hypervisor </b>to manage GCP virtual machines — predefined or custom sets of virtualized resources, including vCPUs, persistent disk space, bandwidth and certain RAM volumes. These instances are split into several <a href="https://cloud.google.com/compute/docs/machine-types">GCP machine types</a> according to a quite straightforward classification.</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1140" height="595" src="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_table_2.png" alt="" class="wp-image-7844" srcset="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_table_2.png 1140w, https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_table_2-768x401.png 768w" sizes="(max-width: 1140px) 100vw, 1140px" /></figure>



<h3>Predefined GCP machines</h3>



<p>As you can see, these virtual machines are split into 4 main categories:&nbsp;</p>



<ul><li>E2 general-purpose instances,&nbsp;</li><li>N1,2,2D family of machines for standard tasks,</li><li>M1, M2 high-memory instances for memory-intensive tasks,</li><li>C2 instances with high vCPU volumes for compute-intensive use</li></ul>



<p>Google Compute Engine allocates the computing resources in units (GCEU) according to 4 main parameters: the CPU power, allocated memory size, egress bandwidth and persistent disk volume. Depending on the combination of these parameters, you can select a machine type best suited for performing the tasks you need to be done. </p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1140" height="470" src="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_N_3.png" alt="" class="wp-image-7843" srcset="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_N_3.png 1140w, https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_N_3-768x317.png 768w" sizes="(max-width: 1140px) 100vw, 1140px" /></figure>



<h3>N machines family</h3>



<p>For example, <b>n1-standard</b> machines come in 8 variations, with every next doubling the resources of the previous one, from <b>1 vCPU with 8 GB of RAM</b> to <b>96 vCPUs with 360 GBs</b> of memory. The persistent disk size is limited to 257 TB in this type, and the egress bandwidth varies from 10 to 32 Gbps. Each vCPU takes one thread in hyper-threading multicore processors like Sandy Bridge, Broadwell, Haswell and other models, used by Google Cloud.</p>



<p>These machines are best suited for running standard applications that consume their resources in a stable way and require a balanced combination of CPU power and memory. As shown above, this scenario is best for serving web and mobile apps, storing a cache of data, supporting media/streaming workloads, etc.</p>



<p>In addition, many of these machines can come in high-memory or high CPU combinations. For example, n1-highmem machines provide more memory per a single vCPU and come in 7 varieties ranging from <b>2 vCPUs with 13 GBs</b> of memory to<b> 96 vCPUs with 624 GBs of RAM</b>. These machines are best suited to running medium-to-large in-memory databases and real-time data analytics or other memory-intensive tasks.</p>



<p>n1-highcpu machines have more vCPU power available per memory unit, namely 0.9 GB of RAM per 1 vCPU. This results in compute-intensive virtual machines best suited for running rendering jobs, supporting online gaming servers, running Electronic Design Automation tasks and complex single-threaded applications. These machines come with 7 options, ranging from <b>2 to 96 vCPUs and 2 to 86.6 GBs</b> of memory.&nbsp;</p>



<p>There also are shared-core machine types, where the customers have access to short-time vCPU power spikes on request. This is great for applications that normally consume just a little resources, but can spike in workload at some moment. You can save a lot by running such applications on n1-micro or e2-micro virtual machines.</p>



<p>In addition. these machines can be also configured according to your custom specs to fit your unique project requirements. Custom machines can be created with any RAM-to-core ratio, up to 6.5 GBs per core.</p>



<p>To sum it up, n1, n2 and n2D machine family has the following characteristics:</p>



<ul><li>provide access to up to 624 GBs of RAm and 96 virtual CPUs</li><li>come in predefined, shared-core and custom variants</li><li>can provide higher core-to-memory or memory to-core core on demand</li><li>benefit from <a href="https://cloud.google.com/compute/docs/sustained-use-discounts">sustained use discounts</a></li><li>can use GPUs for quick completion of CPU-intensive workloads</li></ul>



<p>Thus said, IT Svit uses N1, N2 or N2D family of machines to build flexible system configurations able to handle a variety of resource-intensive tasks both for software delivery and for ongoing infrastructure management.</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1140" height="470" src="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_E_4.png" alt="" class="wp-image-7842" srcset="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_E_4.png 1140w, https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_E_4-768x317.png 768w" sizes="(max-width: 1140px) 100vw, 1140px" /></figure>



<h3>E machines family</h3>



<p>Similarly, e2-standard machines are computing units best suited for small-to-medium tasks that require 16 vCPUs at most and do not require persistent SSDs or local GPUs. These general-purpose machines are perfect as inexpensive instances for running cloud-based Individual Development Environments (IDEs), virtual desktops for enterprise customers, small-scope web applications, smaller database instances with low resource consumption, microservice instances, etc.</p>



<p>E2-standard machines come in 4 configurations, from <b>2 to 16 vCPUs</b> and from <b>8 to 64 GBs</b> of memory. While e2 machines are not eligible for sustained use discounts, they are quite cost-efficient as it is due to their low committed-use pricing and absence of costly components like GPUs or local SSDs.</p>



<p>E2 machines also come in high-memory and high-cpu variants and have the following benefits:</p>



<ul><li>Provide up to 16 vCPUs and 54 GBs of RAM at the lowest price available across all general-purpose GCP machine types.</li><li>Support a <a href="https://cloud.google.com/compute/docs/machine-types#virtio_memory_balloon_device">memory balloon</a> feature</li><li>use the latest Intel or AMD EPYC Rome processors, which are selected automatically when you create an instance, based on availability.</li></ul>



<p>However, due to their specifics, E2 machines have the following limitations:</p>



<ul><li>Don’t support local SSDs, GPUs, nested virtualization or single-tenant nodes</li><li>You cannot control the processor type you get</li><li>No sustained-use discounts.</li></ul>



<p>Nevertheless, IT Svit found e2 general purpose machines to be the best building blocks for inexpensive and resilient cloud infrastructures at scale.</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1140" height="470" src="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_M_5.png" alt="" class="wp-image-7841" srcset="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_M_5.png 1140w, https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_M_5-768x317.png 768w" sizes="(max-width: 1140px) 100vw, 1140px" /></figure>



<h3>M machine family</h3>



<p>M1- or M2-standard virtual machines are intended to use the tasks requiring much higher memory-to-cpu ratios than general purpose n-standard virtual machines. These tasks involve real-time in-memory data processing at scale and in-memory database management (like SAP HANA) or running SQL analytics jobs and so on. To enable this functionality,&nbsp; M1- and M2-standard machine types come with <b>14 to 28 GBs of RAM per vCPU</b>.</p>



<p>However, certain restrictions apply:</p>



<ul><li>Memory-optimized virtual machines don’t allow using regional persistent disks</li><li>Not all Google Availability Zones provide this service</li><li>These instances come with only a limited selection of platforms.</li></ul>



<p>Nevertheless, IT Svit found Google M1 and M2 machines to be extremely cost-efficient for projects that involve resource-intensive in-memory calculations, like real-time Big Data analytics.</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1140" height="470" src="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_C_6.png" alt="" class="wp-image-7840" srcset="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_C_6.png 1140w, https://itsvit.com/wp-content/uploads/2020/09/ItSvit_Google-cloud_C_6-768x317.png 768w" sizes="(max-width: 1140px) 100vw, 1140px" /></figure>



<h3>C2 machine type </h3>



<p>Finally, C2 virtual machines have a superior CPU-to-RAM ratio and are excellent for enabling resource-intensive computations, like running online gaming servers, complex single-threaded applications or rendering new designs. Built using the latest generation processors (Cascade Lake) these machines deliver up to 3.8 GHz all-core turbo CPU power and provide full transparency into the underlying infrastructure, enabling the users to fine-tune their performance.</p>



<p>With <b>4 to 60 vCPUs and 16 to 240 GBs of RAM</b>, C2 machines are very powerful computing units, yet they also have some limitations:</p>



<ul><li>Their <a href="https://cloud.google.com/compute/docs/disks/performance#c2-disk-limits">disk limits</a> and resource quotas differ from those for general-purpose machines</li><li>These machines cannot use regional persistent discs</li><li>C2 family of machines is only available in select regions and on select platforms</li></ul>



<p>IT Svit uses these instances for training Machine Learning models and Artificial Intelligence algorithms, as they provide immense computational capacity and help accomplish these tasks very quickly.</p>



<h2>Google Cloud pricing and discounts</h2>



<p>One of the biggest benefits Google Cloud can offer to its customers is its flexible pricing policy. All VM instances are billed for 1 minute of usage minimum and for every second after that. Thus said, this might seem costly for jobs that run for 5 seconds, but it pays off hugely for tasks that run for hours on end.</p>



<p>Besides, all GCP machine types are susceptible to various pricing discounts unless directly stated otherwise. For example, users can benefit from the following cost reductions:</p>



<ul><li><b>Sustained use discounts</b> — price reductions for using vCPUs and memory in all machine types for prolonged periods (for a larger part of the billing month), as well as for using single-tenant nodes and GPU devices in your operations.</li><li><b>Committed use discounts</b> — price reductions of up to 57% when paying for your SSDs, vCPUs and RAM for 1 or 3 years in advance. Most global corporations follow this route, allowing them to save millions in IT expenses over time.</li><li><b>Preemptible use discounts</b> — price reductions due to using virtual machines from the currently free Google Compute Engine inventory. These instances cost very low but can be terminated (preempted) at any moment, if any other customer pays in full for the resources they consume.<br><br>This approach is best for building nodes for message broker services like Kafka or RabbitMQ. In this case, keeping the whole infrastructure running when no events occur can be very costly, but spinning up the whole system to process new batch of events and go back into the dormant state afterwards helps save a ton of resources while ensuring stable performance of your systems.</li></ul>



<p>As you can see, Google Cloud Platform provides a wide variety of resources enabling its customers to solve various tasks big and small. IT Svit works with GCP for 5+ years and in that time we have gained deep insight and understanding of the GCP machine types and how to use them best. We also have a thorough understanding of using Google PaaS solutions like App Engine, Kubernetes Engine, StackDriver, BigQuery, DataProc and DataFlow. This allows us to build flexible, cost-efficient and transparent infrastructures and workflows that help our customers achieve their business goals. Should you need the same — IT Svit is ready to help, just contact us with your project requirements!</p>The post <a href="https://itsvit.com/blog/what-is-google-cloud-best-used-for-gcp-machine-types-and-services/">What is Google Cloud best used for? GCP machine types and services</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></content:encoded>
					
					<wfw:commentRss>https://itsvit.com/blog/what-is-google-cloud-best-used-for-gcp-machine-types-and-services/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Google Cloud Composer vs Astronomer: what to choose?</title>
		<link>https://itsvit.com/blog/google-cloud-composer-vs-astronomer-what-to-choose/</link>
					<comments>https://itsvit.com/blog/google-cloud-composer-vs-astronomer-what-to-choose/#respond</comments>
		
		<dc:creator><![CDATA[Vladimir Fedak]]></dc:creator>
		<pubDate>Thu, 03 Sep 2020 08:00:00 +0000</pubDate>
				<category><![CDATA[Articles]]></category>
		<category><![CDATA[Blog]]></category>
		<category><![CDATA[Big Data]]></category>
		<category><![CDATA[Cloud Computing]]></category>
		<guid isPermaLink="false">https://itsvit.com/?p=7816</guid>

					<description><![CDATA[<p>Selecting the right approach to building distributed data pipelines requires finding a good managed cloud computing solution, so we compare Google Cloud Compose with Astronomer. Big Data processing was cloud platform-specific before the introduction of Airflow from Airbnb. The platform built on aggregating the venue booking offers from multiple providers across the globe obviously needed [&#8230;]</p>
The post <a href="https://itsvit.com/blog/google-cloud-composer-vs-astronomer-what-to-choose/">Google Cloud Composer vs Astronomer: what to choose?</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></description>
										<content:encoded><![CDATA[<p>Selecting the right approach to building distributed data pipelines requires finding a good managed cloud computing solution, so we compare Google Cloud Compose with Astronomer.</p>



<span id="more-7816"></span>



<p><a href="https://itsvit.com/services/big-data/">Big Data</a> processing was cloud platform-specific before the introduction of Airflow from Airbnb. The platform built on aggregating the venue booking offers from multiple providers across the globe obviously needed a system for forming a holistic workflow orchestration landscape throughout many infrastructure providers. After the Airflow project was initially built and donated to Apache, a huge and passionate community has invested lots of effort into turning it the best available data pipeline orchestration tool around.</p>



<p>However, handling complex data processing workflows is daunting enough to be worrying about the underlying infrastructure performance at the same time. This is why the need for managed Airflow services became obvious, and in 2018 two main competitors entered the field: Google Cloud Composer and Astronomer, which are microservice-architected hosted solutions that use Directed Acyclic Graphs or DAGs to manage data processing pipelines. Let’s dive deeper and compare these two alternatives, so you will be able to make an informed decision when selecting between them.&nbsp;</p>



<p>Of course, nobody forces your hand to go for paid hosting platforms and you are perfectly allowed to download the latest stable Airflow build, master its documentation and configure the underlying infrastructure and processes yourself. However, this approach is not cost-efficient, as it is a time-consuming process of reinventing the wheel and following the footprints of either Astronomer or Cloud Composer, without having access to their wealth of technical expertise.</p>



<h2><b>Cloud Composer vs Astronomer</b></h2>



<p>We will compare Google Cloud Composer to Astronomer by several parameters:</p>



<ol><li>Type of infrastructure used</li><li>Type of operators applied</li><li>DAG architecture and usage</li><li>Usage of code templates</li><li>Usage of RESTful APIs</li></ol>



<p>These are the most distinguishing features, but Cloud Composer and Astronomer have lots in common:</p>



<ul><li>Both have pre-configured deployment scenarios, so instead of spending days and weeks to build and configure the needed infrastructure, you get a working Airflow environment in minutes.</li><li>Both are managed services, so dedicated DevOps teams (Google Cloud or Astronomer Cloud respectively) handle the infrastructure maintenance tasks</li><li>Both enable horizontal scaling out of the box, so you can add new Airflow environments with ease and never worry about scaling and load balancing</li><li>Both provide CLI tools for DAG handling, though Cloud COmposer also provides a web UI dashboard for managing Airflow webserver and DAGs with ease.</li><li>Both provide an immense PyPI (Python Package Index) to allow you to leverage all the libraries needed in your data processing workflows.</li><li>Both work with a wide list of plugins to augment the operations you might need to perform</li><li>Both support email alerting and multiple monitoring features to help you keep the hand on the pulse of your systems, though Cloud Composer benefits from direct integration with StackDriver dashboards.</li><li>Both provide detailed developer documentation on the usage of their solutions, as well as paid support on subscription basis.&nbsp;</li></ul>



<p>Thus said, let’s take a look at the differences between Cloud Composer and Astronomer.</p>



<ol><li><b>Airflow infrastructure</b></li></ol>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1141" height="269" src="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_Airflow-infrastructure_2.png" alt="" class="wp-image-7822" srcset="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_Airflow-infrastructure_2.png 1141w, https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_Airflow-infrastructure_2-768x181.png 768w" sizes="(max-width: 1141px) 100vw, 1141px" /></figure>



<p>Google Cloud Composer deploys Airflow projects to its Kubernetes clusters using Celery Executor to store Airflow Webserver, Redis message broker, Postgres for metadata, Flower for monitoring, as well as Airflow Scheduler and Workers as nodes on a Kubernetes cluster. After the infrastructure is designed and all connectors are configured, the same scheme can be used with Google, AWS, Azure, DigitalOcean or any on-prem Kubernetes cluster.</p>



<p>By default, Astronomer deploys Airflow projects to GKE running on Astronomer cloud, but it has step-by-step guides to deploying your Airflow environments to any of the major cloud providers or on-prem infrastructure. Astronomer uses Mesos or Kubernetes Executors as alternatives to Celery.</p>



<ol start="2"><li><b>Operators applied</b></li></ol>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1141" height="269" src="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_Operators-applied_3.png" alt="" class="wp-image-7821" srcset="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_Operators-applied_3.png 1141w, https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_Operators-applied_3-768x181.png 768w" sizes="(max-width: 1141px) 100vw, 1141px" /></figure>



<p>Airflow supports a wide range of <a href="https://airflow.apache.org/_api/airflow/operators/index.html">common operators</a> and most of these are supported by Google. Cloud Composer also works with a wide range of plugins and allows configuring any webhooks you need to trigger the Airflow data pipeline execution.</p>



<p>Astronomer supports the common plugins and custom operators, but the chance of you facing the need to develop another custom operator for your project is much higher with Astronomer. For example, while with Google 100% of DevOps work will be handled by the GCP team, working with the Astronomer team requires your in-house team to have a good understanding of DevOps workflows and tools. Otherwise (like when you need Airflow purely for data processing needs and have no in-house DevOps expertise), you will need to opt for the Astronomer Enterprise Cloud solution.</p>



<ol start="3"><li><b>DAG architecture</b></li></ol>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1141" height="269" src="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_DAG-architecture_4.png" alt="" class="wp-image-7820" srcset="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_DAG-architecture_4.png 1141w, https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_DAG-architecture_4-768x181.png 768w" sizes="(max-width: 1141px) 100vw, 1141px" /></figure>



<p>Cloud Composer offers a convenient DAG management dashboard, where you can combine warious modules into DAG Runs and build workflow pipelines. Each of the individual DAG components is idempotent, meaning they are self-contained and have all their connectors, hooks and dependencies stored with them, so connecting two modules in the dashboard and dropping a ready file into a DAG folder on your Google Storage leads to automatically applying all the configurations. All DAGs are kept as simple as possible to minimize the risk of misconfigured interdependencies slowing or halting the performance of your Airflow pipelines.</p>



<p>With Astronomer, you have a similar dashboard and a library of ready images, but there is no drag-and-drop option and all the configuration must be performed via Python scripts (R is announced but not implemented yet).</p>



<ol start="4"><li><b>Code templates</b></li></ol>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1141" height="269" src="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_Code-templates_5.png" alt="" class="wp-image-7819" srcset="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_Code-templates_5.png 1141w, https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_Code-templates_5-768x181.png 768w" sizes="(max-width: 1141px) 100vw, 1141px" /></figure>



<p>The default template engine for Airflow is Jinja, well-known to most Python developers working with Flask framework. It allows building neat and flexible templates that reduce the hurdle of writing new code for each operation. However, using code templates adds another layer of complexity to software engineering — but it can be a stepping stone for pure web developers transitioning into data processing operations.</p>



<p>With Google Cloud Composer, you get a library of templates to use, but the need in them is minimal, as it is a 100% managed service.</p>



<p>With Astronomer, you are free to build the templates you need, and the Astronomer team (which includes two of the initial Airflow developers and other tech talents) works on constantly increasing the number of custom code templates, webhooks and connectors available to the customers.</p>



<ol start="5"><li><b>RESTful API handling</b></li></ol>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1141" height="269" src="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_RESTful-API-handling_6.png" alt="" class="wp-image-7818" srcset="https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_RESTful-API-handling_6.png 1141w, https://itsvit.com/wp-content/uploads/2020/09/ItSvit_GCC-vs-Astronomer_RESTful-API-handling_6-768x181.png 768w" sizes="(max-width: 1141px) 100vw, 1141px" /></figure>



<p>Airflow uses RESTful APIs for interacting with external system modules. With Google Cloud, this means Google’s AI and ML products and system components, first and foremost. However, there are Google guides on moving your Airflow environments to external destinations or replacing </p>



<p>With Astronomer, you are free to use these APIs from the get-go to deploy your Airflow projects to on-prem Kubernetes clusters, AWS, Azure, etc. — or include components from these cloud platforms into your infrastructure.</p>



<p>Use cases for RESTful APIs with Airflow include the following scenarios:</p>



<ul><li><a href="https://medium.com/google-cloud/using-airflow-experimental-rest-api-on-google-cloud-platform-cloud-composer-and-iap-9bd0260f095a">Spinning up Kubernetes clusters for data processing based on external https requests</a>.</li><li><a href="https://blog.godatadriven.com/airflow-experimental-rest-api">Launching a workflow based on a message appearing in your message broker or data storage</a>.</li><li><a href="https://medium.com/adobetech/adobe-experience-platform-orchestration-service-with-apache-airflow-952203723c0b">Building full-scale Machine Learning platforms for processing data on demand</a></li></ul>



<p>Thus said, using REST API turns Airflow into a highly flexible solution that can serve multiple business needs in a wide variety of scenarios.</p>



<h2><b>Conclusions: when to use Astronomer or Cloud Composer?</b></h2>



<p>To wrap it up, let’s talk about what matters most for many businesses &#8211; costs. While Google showcases Cloud Composer pricing openly, the scheme of price formation is not quite transparent, as data storage and some other expenses are added to your overall monthly bill. However, various sources indicate the average price of a single Airflow environment to be around <b>$300/mo. with Google</b>. Of course, for this price, you get an end-to-end solution with in-depth help documentation and top-notch Google support.</p>



<p>Astronomer Cloud is essentially the Google Cloud reseller, as GKE is its default destination for Airflow environments. However, <b>Astronomer charges only $110/mo.</b> to start an Airflow project with a Local Executor. The price is nearly three times lower — but the level of user convenience is not quite as high with Astronomer, both in terms of DAG configuration and in terms of availability of plugins, connectors and API integrations with other projects.</p>



<p>Therefore, you can either go for rock-solid customer experience at quite an affordable price with GCP or select a much more affordable solution with more configuration overhead with Astronomer. keep in mind though, that both of these costs can multiply quite quickly, should you configure Airflow incorrectly,</p>



<p>But what to do if your team does not have the DevOps expertise required to plan and execute complex distributed workflows and spending time waiting for <a href="https://itsvit.com/services/big-data/google-cloud-big-data/">Google Cloud</a> support response is too costly? Contact IT Svit, one of the leaders of the worldwide Managed <a href="https://itsvit.com/services/devops/">DevOps Services</a> market! We would be glad to help!</p>The post <a href="https://itsvit.com/blog/google-cloud-composer-vs-astronomer-what-to-choose/">Google Cloud Composer vs Astronomer: what to choose?</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></content:encoded>
					
					<wfw:commentRss>https://itsvit.com/blog/google-cloud-composer-vs-astronomer-what-to-choose/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>What is Google Cloud Composer: all you need to know</title>
		<link>https://itsvit.com/blog/what-is-google-cloud-composer-all-you-need-to-know/</link>
					<comments>https://itsvit.com/blog/what-is-google-cloud-composer-all-you-need-to-know/#respond</comments>
		
		<dc:creator><![CDATA[Vladimir Fedak]]></dc:creator>
		<pubDate>Thu, 20 Aug 2020 09:55:00 +0000</pubDate>
				<category><![CDATA[Articles]]></category>
		<category><![CDATA[Blog]]></category>
		<category><![CDATA[Cloud Computing]]></category>
		<guid isPermaLink="false">https://itsvit.com/?p=7803</guid>

					<description><![CDATA[<p>Every business might face the need to build hybrid or multi-cloud infrastructures, for data security or other reasons. Doing this from scratch can be a system architect’s nightmare due to the need to correctly configure and monitor all the multiple interdependencies between various infrastructure components. Meet Google Cloud Composer — a managed service for building, [&#8230;]</p>
The post <a href="https://itsvit.com/blog/what-is-google-cloud-composer-all-you-need-to-know/">What is Google Cloud Composer: all you need to know</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></description>
										<content:encoded><![CDATA[<span id="more-7803"></span>
<!--noteaser-->



<p>Every business might face the need to build hybrid or multi-cloud infrastructures, for data security or other reasons. Doing this from scratch can be a system architect’s nightmare due to the need to correctly configure and monitor all the multiple interdependencies between various infrastructure components. Meet Google Cloud Composer — a managed service for building, scheduling and running workflow orchestration pipelines for hybrid and multi-cloud environments. It uses open-source Apache Airflow and Python to avoid vendor lock-in and has steadily grown in popularity since its release in 2017. Why is it so good and what can it do for your business? Let’s take a closer look!</p>



<p>Cloud Composer uses DAGs — direct acyclic graphs to visually represent the pipelines you create. This is a very simple way to design, monitor and troubleshoot your infrastructure spanning a variety of platforms. Every module on the graph comes complete with webhooks, APIs, pre-configured connectors and all other network dependencies. This way, you can simply connect a module to another one on a graph, and all the required configuration will happen under the hood.</p>



<p>This is very convenient for startups and small-to-medium enterprises alike, as it allows them to build top-notch hybrid and multi-cloud infrastructures and workflows without having in-depth technical expertise or paying a fortune for DevOps support from Google or its affiliated partners. In addition, Cloud Composer is deeply integrated with other Google Cloud services like Google Dataflow and Dataproc, Big Query, Google Kubernetes Engine, Google Data Storage and other services, so building even complex multicomponent infrastructures is much easier than before.</p>



<p>Even more importantly, Cloud Composer informs if there are some issues in the underlying components, so monitoring and troubleshooting your infrastructure becomes even easier. Below we take a look at Google Cloud Composer’s main concepts, benefits and use cases.</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1140" height="595" src="https://itsvit.com/wp-content/uploads/2020/08/ItSvit_Google-Cloud-Composer_main-concepts_2.png" alt="" class="wp-image-7807" srcset="https://itsvit.com/wp-content/uploads/2020/08/ItSvit_Google-Cloud-Composer_main-concepts_2.png 1140w, https://itsvit.com/wp-content/uploads/2020/08/ItSvit_Google-Cloud-Composer_main-concepts_2-768x401.png 768w" sizes="(max-width: 1140px) 100vw, 1140px" /></figure>



<h2><b>Google Cloud Composer main concepts</b></h2>



<p>Google used Apache Airflow, an open-source project for building modular architectures and workflows, to enable the Composer functionality — and now Google is one of the biggest contributors to the ongoing development of Airflow. However, this has lead to certain limitations. For example, as the Composer uses Airflow logic, it leverages the pretty rigid system of key components and dependencies between them.&nbsp;</p>



<p>This is somewhat similar to on-prem deployments, where you have to use only the resources available on a specific machine and perform operations in a specific order to ensure they succeed. Therefore, Google Composer users have to follow several important rules described in detail in corresponding <a href="https://cloud.google.com/composer/docs">Composer FAQ documentation</a>.</p>



<p>For starters, Airflow works with microservices only and to deploy it successfully, you must provision several Google Cloud modules forming a Cloud Composer environment. You can have as many such environments as you need, grouped into Composer Projects. Every such project is run on Google Kubernetes Engine, interacts with required Google services via built-in connectors and is completely self-sustainable.&nbsp;</p>



<p>Not all <a href="https://cloud.google.com/about/locations">Google Cloud regions</a> support Composer, and it has to run within a Compute Engine zone. However, both simple projects with one Composer environment per region, or complex ones with multiple environments spanning multiple regions or on-prem datacenters can be configured based on your project needs. All Airflow components communicate with Google Cloud products via open APIs.</p>



<p>Your Composer environment includes 2 major parts — a Google-run tenant project ad your customer project.<b> Tenant project</b> runs key system components like Cloud SQL and App Engine. This provides an additional layer of security, access control and identity management.</p>



<p><b>Cloud SQL </b>is needed to store Airflow metadata and protect these sensitive details of connection and workflow configuration. To minimize the risk of mishandling this data, Composer limits the database access to a <a href="https://cloud.google.com/iam/docs/service-accounts">custom service account</a> — an entity used by a VM to make API calls, so not a single person has access to it. In addition, all Airflow data is automatically backed up regularly to minimize the potential impact of data loss.</p>



<p><b>App Engine</b> is needed to run the Airflow webserver. It comes with IAM policy embedded, so you have granular control over who can access your Composer resources. For the sake of ease of configuration, Airflow webserver can come preconfigured by Google.</p>



<p>The <b>customer project</b> operates Google Kubernetes Engine, Cloud Storage, Logging and Monitoring features.</p>



<p><b>Google Kubernetes Engine</b> provides an infrastructure where your key Composer components like Airflow scheduler, CeleryExecutor and worker nodes will run. CeleryExecutor uses Redis message broker to ensure workflow consistency across a variety of infrastructures that might restart their components independently.</p>



<p><b>Cloud Storage</b> is a data storage bucket for storing data, logs, DAGs, data dependencies and various plugins. Simply placing a DAG in your storage forces Composer to automatically configure all the required dependencies</p>



<p><b>Cloud Logging and Monitoring</b> integrate with Composer by default, providing you with a centralized dashboard to view all the logs and metrics for your project. As Airflow uses a data streaming logic, you can configure your systems to consume the events in real-time and be able to provide useful insights on your system-level data and dependencies on the fly.</p>



<p>To wrap it up, Cloud Composer is a fully managed workflow orchestration service that is quite easy to configure and starts providing value from day one.</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1140" height="595" src="https://itsvit.com/wp-content/uploads/2020/08/ItSvit_Google-Cloud-Composer_key-benefits_3.png" alt="" class="wp-image-7806" srcset="https://itsvit.com/wp-content/uploads/2020/08/ItSvit_Google-Cloud-Composer_key-benefits_3.png 1140w, https://itsvit.com/wp-content/uploads/2020/08/ItSvit_Google-Cloud-Composer_key-benefits_3-768x401.png 768w" sizes="(max-width: 1140px) 100vw, 1140px" /></figure>



<h2><b>Cloud Composer key benefits</b></h2>



<p>We briefly list the reasons why Cloud Composer is a worthy tool for your IT projects:</p>



<ol><li>It allows building a multi-cloud environment in a simple way to combine all your data, workflows and services into a holistic system.</li><li>It is portable and flexible, as it is built upon Apache Airflow open-source project and saves you from vendor lock-in.</li><li>If you need a hybrid cloud solution to meet data security requirements — Composer is the best way to go to ensure safe and transparent data transfer between on-prem and cloud-based components.</li><li>It is integrated with Big Query, Dataproc, Dataflow, Google AI platform, Cloud Pub/Sub and Data Storage, giving you an ability to use the latest Google tools for Big Data processing with ease.</li><li>It is written in Python, so the learning curve is quite low and you can master this service in no time.</li><li>DAGs and convenient dashboards ease the creation and configuration of your workflows, as well as troubleshooting them to the roots of any issue.</li><li>Due to being a fully managed service, Composer is all about designing, running and managing workflows for your projects — all infrastructure configuration is one once and is fully automated since then.</li></ol>



<p>Thus said, Google Cloud Composer is a great solution for startups that want to leverage the full potential of Google Cloud or their projects. Due to extensive documentation and well-thought-through operational practices, having Python skills is nearly all you need to create modular, resilient and cost-efficient infrastructures for your projects, wherever they run.</p>



<p>Should you have any more details regarding Google Cloud Composer — IT Svit would be glad to answer. Actually, over the course of the next few articles, we will discuss the scenarios to use Composer with, possible alternatives and use cases. If you need help configuring or optimizing Cloud Composer environments — let us know, we are ready to assist!</p>The post <a href="https://itsvit.com/blog/what-is-google-cloud-composer-all-you-need-to-know/">What is Google Cloud Composer: all you need to know</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></content:encoded>
					
					<wfw:commentRss>https://itsvit.com/blog/what-is-google-cloud-composer-all-you-need-to-know/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Overview of Managed Airflow by Google Cloud Composer</title>
		<link>https://itsvit.com/blog/overview-of-managed-airflow-by-google-cloud-composer/</link>
					<comments>https://itsvit.com/blog/overview-of-managed-airflow-by-google-cloud-composer/#comments</comments>
		
		<dc:creator><![CDATA[Vladimir Fedak]]></dc:creator>
		<pubDate>Tue, 30 Jun 2020 10:51:27 +0000</pubDate>
				<category><![CDATA[Articles]]></category>
		<category><![CDATA[Blog]]></category>
		<category><![CDATA[Cloud Computing]]></category>
		<guid isPermaLink="false">https://itsvit.com/?p=7723</guid>

					<description><![CDATA[<p>Cloud computing widespread adoption opened possibilities of building complex systems spanning multiple cloud platforms and on-prem facilities. However, setting up the required workflows required to make such systems work requires a great deal of scripting and troubleshooting to make sure all the dependencies work as intended. Apache Airflow is a great microservice-architected open-source project for [&#8230;]</p>
The post <a href="https://itsvit.com/blog/overview-of-managed-airflow-by-google-cloud-composer/">Overview of Managed Airflow by Google Cloud Composer</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></description>
										<content:encoded><![CDATA[<span id="more-7723"></span>
<!--noteaser-->



<p>Cloud computing widespread adoption opened possibilities of building complex systems spanning multiple cloud platforms and on-prem facilities. However, setting up the required workflows required to make such systems work requires a great deal of scripting and troubleshooting to make sure all the dependencies work as intended. Apache Airflow is a great microservice-architected open-source project for building and managing distributed systems and workflows. Cloud Composer is a managed service of Airflow from Google Cloud Platform, and today we briefly overview its key features, pros and cons.</p>



<p>First of all, what is Google Cloud Composer? It is a fully-managed service for designing, running, scheduling and troubleshooting distributed workflows for hybrid cloud and multi-cloud systems. Due to it being managed, developers and system administrators can concentrate on designing and running their workflows, instead of handling the needs of scaling, backups load balancing and other DevOps aspects of such operations.&nbsp;</p>



<p>Written in Python atop open-source Apache Airflow project, Cloud Composer can be integrated with a wide variety of Google services and open-source products via APIs, allowing any business to build complex infrastructures and workflows in a simple and understandable way with Google and use it anywhere later on. With quite an affordable pricing, Cloud Composer can become a one-stop-shop for many businesses in need of building a reliable workflow management solution. Below we list the main features of Cloud Composer.</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1141" height="595" src="https://itsvit.com/wp-content/uploads/2020/06/Itsvit_Google-Cloud-Composer_main-features_2.png" alt="" class="wp-image-7726" srcset="https://itsvit.com/wp-content/uploads/2020/06/Itsvit_Google-Cloud-Composer_main-features_2.png 1141w, https://itsvit.com/wp-content/uploads/2020/06/Itsvit_Google-Cloud-Composer_main-features_2-768x400.png 768w" sizes="(max-width: 1141px) 100vw, 1141px" /></figure>



<h2>Google Cloud Composer main features</h2>



<p>Every product from Google shares the same paradigm: a well-thought-through approach to the system architecture with deep integration with the rest of Google and an open-source ecosystem, built with attention to detail and positive customer experience at its core. Google Cloud Composer shares these characteristics through the following features:</p>



<ol><li><b>Portability</b>. Built atop Apache Airflow, your Composer project can be taken to any other platform and work there successfully, after adjusting the underlying infrastructure.&nbsp;&nbsp;</li><li><b>Multi-cloud functionality</b>. Built-in connectors allow replacing Google Cloud services with other cloud products should the need be, avoiding vendor lock-in.</li><li><b>Hybrid cloud operations</b>. Cloud Composer ensures safe transfer and processing of data stored at your on-prem data warehouses, allowing the businesses to combine the unlimited computational scalability of the cloud with the security of on-prem operations.</li><li><b>Python</b>. Being the most popular programing language for Big Data operations nowadays, Python was obviously the best choice for building Apache Airflow. Due to using Python, developers can quickly design, troubleshoot and launch workflows and pipelines for their projects, without having to worry about the DevOps side of things.</li><li><b>Integration</b>. Cloud Composer interacts with other services via APIs and has native support for Google products like Big Query, Cloud Datastore, Dataflow and Dataproc, AI Platform, Cloud Pub/Sub and Cloud Storage. However, any of these components can be easily replaced with AWS or Azure analogs, should you need this, due to a variety of connectors, plugins and extensions available.</li><li><b>Resilience</b>. Built atop Google infrastructure, Cloud Composer is a very fault-tolerant system that can ensure the reliability of your operations and provides convenient dashboards for system performance monitoring and issue root cause troubleshooting.</li></ol>



<p>Let’s take a quick look at the pros and cons of working with Cloud Composer.</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1141" height="595" src="https://itsvit.com/wp-content/uploads/2020/06/Itsvit_Google-Cloud-Composer_benefits-and-downsides_3.png" alt="" class="wp-image-7725" srcset="https://itsvit.com/wp-content/uploads/2020/06/Itsvit_Google-Cloud-Composer_benefits-and-downsides_3.png 1141w, https://itsvit.com/wp-content/uploads/2020/06/Itsvit_Google-Cloud-Composer_benefits-and-downsides_3-768x400.png 768w" sizes="(max-width: 1141px) 100vw, 1141px" /></figure>



<h2>Cloud Composer benefits and downsides</h2>



<p>Many Big Data architects and developers of data-driven software products seek for a way to get a hosted solution and build the systems they need without having to configure the underlying infrastructure. Cloud Composer provides the following advantages in this regard:</p>



<ol><li><b>Speed and ease of configuration</b>. Once you register a Google Cloud account, configuring Composer is literally a couple of clicks away. During the 20 minutes needed to launch your Composer project, you can simply select the Python libraries you are going to use from a detailed PyPI list, configure the needed environment variables, etc. — and voila, you are good to go.</li><li><b>The simplicity of deployment</b>. Composer projects are build using DAGs — Directed Acyclic Graphs, which are stored in a dedicated folder in your Google Cloud Storage. You have a detailed dashboard, where you can compose a DAG from a variety of available components, and simply drag-and-drop it to this folder — the service does all the remaining configuration itself, and the working data pipeline appears in the UI of your Airflow webserver. Should you prefer CLI operations to drag-and-drop — no problem, this can be done through <em>gcloud</em>.</li><li><b>Clean UI</b>. Cloud Composer is a managed service, meaning most of the configuration happens behind the scenes and your dashboard is not clogged with multiple checkboxes. Your Google Cloud dashboard connects to the DAG folder and to the Airflow webserver, so you can easily troubleshoot your pipelines in real-time.&nbsp;</li><li><b>The latest Python version supported</b>. Upon release, Cloud Composer worked with Python 2.7 only, but as of now it supports Python 3.6 and works hard to implement all the latest Python features.</li></ol>



<p>The only serious downside of Google Cloud Composer is that it is a managed service, meaning you pay a bit more due to getting a ready solution instead of configuring the infrastructure yourself. However, <b>$250/mo</b>. is not a huge price for a single Composer project, while it might be a bit too much for pet projects.&nbsp;</p>



<p>On the other hand, as a managed service, Cloud Composer has limits to the number of services and integrations it supports. In some cases, especially when dealing with legacy on-prem infrastructures, you might need to build custom connectors or APIs that are not readily available from Google. In addition, the troubleshooting of DAG connectors requires in-depth expertise with Google Cloud Platform operations.</p>



<h2>Conclusions: Cloud Composer is a solid choice </h2>



<p>Thus said, Google Cloud Composer still is a solid choice for any business or entrepreneur who needs to build a reliable data processing ecosystem. It is a polished solution with extensive documentation, allowing any customer to learn the basics in a short time. However, you are better off having access to a solid GCP expertise to speed up the initial troubleshooting while building your data pipelines and/or build/configure custom connectors and APIs when working with legacy infrastructure.</p>



<p>IT Svit has this expertise based on a large number of GCP-based projects we successfully accomplished for our customers. We are ready to help you use Google Cloud Composer with maximum cost-efficiency, so feel free to contact us with any questions regarding managed Airflow operations — we would be glad to answer!</p>The post <a href="https://itsvit.com/blog/overview-of-managed-airflow-by-google-cloud-composer/">Overview of Managed Airflow by Google Cloud Composer</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></content:encoded>
					
					<wfw:commentRss>https://itsvit.com/blog/overview-of-managed-airflow-by-google-cloud-composer/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>IT Svit DevOps security skills</title>
		<link>https://itsvit.com/blog/it-svit-devops-security-skills/</link>
					<comments>https://itsvit.com/blog/it-svit-devops-security-skills/#respond</comments>
		
		<dc:creator><![CDATA[Vladimir Fedak]]></dc:creator>
		<pubDate>Wed, 22 Apr 2020 22:00:00 +0000</pubDate>
				<category><![CDATA[Articles]]></category>
		<category><![CDATA[Blog]]></category>
		<category><![CDATA[Cloud Computing]]></category>
		<category><![CDATA[DevOps]]></category>
		<category><![CDATA[Outsourcing]]></category>
		<guid isPermaLink="false">https://itsvit.com/?p=7616</guid>

					<description><![CDATA[<p>The outbreak of COVID-19 has put many industries on hold for quarantine and forced many companies to reassess the way they work and interact with their customers. Working remotely and interacting with customers online quickly becomes the mainstream for all businesses and organizations that can function that way. However, working under the Waterfall project management [&#8230;]</p>
The post <a href="https://itsvit.com/blog/it-svit-devops-security-skills/">IT Svit DevOps security skills</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></description>
										<content:encoded><![CDATA[<span id="more-7616"></span>
<!--noteaser-->



<p>The outbreak of COVID-19 has put many industries on hold for quarantine and forced many companies to reassess the way they work and interact with their customers. Working remotely and interacting with customers online quickly becomes the mainstream for all businesses and organizations that can function that way. However, working under the Waterfall project management model no longer suffices, as you have to adapt quickly to rapidly changing customer preferences.</p>



<p>DevOps workflows provide the needed functionality, but <a href="https://itsvit.com/services/devops/">DevOps</a>, as an approach to software delivery and cloud infrastructure management, is a double-edged sword. DevOps methods allow configuring and managing cloud resources at scale with ease — but a chance of misconfiguration and mishandling your data and system is greatly increased. This is why infrastructure security audit is one of the most frequent requests IT Svit has to deal with — and we have compiled pretty thorough expertise in all aspects of enabling DevOps security with AWS, GCP and other infrastructures.</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="1141" height="595" src="https://itsvit.com/wp-content/uploads/2020/04/ItSvit_DevOps-sec-skills_conclusion_2.png" alt="" class="wp-image-7617" srcset="https://itsvit.com/wp-content/uploads/2020/04/ItSvit_DevOps-sec-skills_conclusion_2.png 1141w, https://itsvit.com/wp-content/uploads/2020/04/ItSvit_DevOps-sec-skills_conclusion_2-768x400.png 768w" sizes="(max-width: 1141px) 100vw, 1141px" /></figure>



<p>Below are IT Svit DevOps security skills and tasks we apply them to:</p>



<ul><li><b>Static code analysis</b>. Our engineers use SonarQube, PEP (Python), and PSR (PHP) for the early discovery of bugs and vulnerabilities and following the code design best practices.</li><li><b>Multi-Factor Authentication</b>. We use Pritunl VPN for configuring secure and personalized infrastructure access.</li><li><b>Firewall configuration</b>. We have ample experience in using IP tables, various Cisco, Mikrotik, and PfSense tools for setting up explicit access to internet-facing components, filtering, routing and port forwarding.</li><li><b>Cluster firewall</b>. We are well-versed in configuring Kubernetes cluster network policies for enabling granular network access restriction.</li><li><b>AWS Firewall</b>. We had ample experience in using AWS Security Groups and Network ACL for setting up explicit access to internet-facing components and providing granular network access restriction.</li><li><b>AWS Web Application Firewall</b>. This tool is useful for checking HTTP headers and creating ACL for the protection of an application or API.</li><li><b>Intrusion Detection and Intrusion Prevention</b>. This can be done using <em>snort </em>for discovering and preventing possible network intrusion points.</li><li><b>Intrusion detection</b>. We are actively using <em>sysdig Falco</em> for discovering OS intrusion attempts. These can include attempts of starting new processes, editing files within unwanted locations (/etc, /var/lib, etc.), executing bash commands, etc.</li><li><b>Updates and configuration management</b>. IT Svit is using Ansible for this. We store configuration in Git-based repositories and use Ansible Vault for sensitive data encryption. Alternatively, we can use OpsWorks to store configuration in Git-based repositories and provision AWS Stacks of EC2 hosts.</li><li><b>Storage encryption</b>. This can be done using LUKS. We enable storage encryption for cloud and non-cloud environments and use AWS KMS for encrypting access to EBS, S3 and other AWS services.</li><li><b>Environment management</b>. This is the core task for any enterprise using Active Directory and LDAP. The user profile is saved on the network storage, so when the user logs in from any PC in the same domain — he/she receives the user data: Downloads, Documents, Browser history, emails, etc.</li><li><b>K8s RBAC + KeyCloack + LDAP</b>. This toolchain is useful for enabling authentication and authorization services (LDAP + GitLab/Jenkins/Redmine/Youtrack/Grafana, LDAP + Windows7, LDAP + LinuxUbuntu Setup IAM credentials to containers running inside a Kubernetes cluster based on annotations (kube2iam))</li><li><b>AWS Identity and Access Management</b>. We are using it with Active Directory for configuring password policies and credentials rotation.</li><li><b>RBAC using AD Groups</b>. This provides explicit access to resources.</li><li><b>RBAC using Kubernetes Roles</b>. This helps grant explicit privileges to users and system processes on components.</li><li><b>RBAC using AWS IAM Roles</b>. We have experience in assigning roles with least-privilege default access so users gain permissions only after assuming a specific role. This also enables configuring explicit permissions on resources.</li><li><b>RBAC using AD and LDAP</b>. We can configure Single Sign-On feature and password policies (complexity, rotation). It is useful for explicit access management.</li><li><b>Credentials management</b>. This can be done using Hashicorp Vault or AWS Secrets Manager. We can secure explicit credentials access from applications.</li><li><b>Subnets management</b>. Using Private, Public Subnets and NAT Gateway we can secure internal infrastructure.</li><li><b>Secure network access to internal infrastructure</b>. We do this using Windows AD and Cisco ASA to enable Single Sign-On at the VPN level. Alternatively, this can be done using bastion hosts as an SSH Proxy hosts. There is no direct access to the bastion host from outside.</li><li><b>Secure network access through a VPN</b>. This is done through Public Key Infrastructure. Users have certificates within their clients with a specific TTL. When TTL expires or user access is revoked using CRL — the user loses the option to connect to a VPN host.</li><li><b>Reverse proxy and load balancing</b>. We do it using AWS: Classic Load Balancer, Application Load Balancer, Network Load Balancer. Otherwise, this can be done using Nginx to ensure load distribution and availability.</li><li><b>AWS Cognito</b>. We can set up it as the authentication and authorization service for distributed mobile applications with AWS API Gateway.</li><li><b>AWS Directory Service</b>. Another way to provide authentication and authorization is through configuring VDI infrastructure and using a Directory Service.</li><li><b>Email encryption</b>. We provide this service using PGP for secure email exchange.</li><li><b>Antivirus management</b>. IT Svit uses Kaspersky Endpoint Security for centralized antivirus management.</li><li><b>Subnets management</b>. We are experienced with using separate network layers (physical, VLAN) for separating different traffic e.g. public, private, backup, etc.</li><li><b>Updates and configuration management</b>. IT Svit uses the AD Group Policy for managing host settings and access rights for the distributed enterprise systems.</li></ul>



<p>As you see, IT Svit can handle all aspects of DevOps security configuration in a variety of software ecosystems. If you want to benefit from IT Svit DevOps security skills — let us know your project specifications, and we would be glad to assist!</p>The post <a href="https://itsvit.com/blog/it-svit-devops-security-skills/">IT Svit DevOps security skills</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></content:encoded>
					
					<wfw:commentRss>https://itsvit.com/blog/it-svit-devops-security-skills/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Types of cloud computing: all you need to know</title>
		<link>https://itsvit.com/blog/types-of-cloud-computing-all-you-need-to-know/</link>
					<comments>https://itsvit.com/blog/types-of-cloud-computing-all-you-need-to-know/#respond</comments>
		
		<dc:creator><![CDATA[Vladimir Fedak]]></dc:creator>
		<pubDate>Sun, 29 Mar 2020 22:00:00 +0000</pubDate>
				<category><![CDATA[Articles]]></category>
		<category><![CDATA[Blog]]></category>
		<category><![CDATA[Cloud Computing]]></category>
		<category><![CDATA[Outsourcing]]></category>
		<guid isPermaLink="false">https://itsvit.com/?p=7424</guid>

					<description><![CDATA[<p>20 years ago we walked around with floppy disks. 15 years ago USB drives were thought the best way to transfer data between computers fast — but then Amazon launched AWS, its public cloud computing platform and the world has changed forever. Nowadays, everyone from freelancers to startups and global enterprises uses various cloud computing [&#8230;]</p>
The post <a href="https://itsvit.com/blog/types-of-cloud-computing-all-you-need-to-know/">Types of cloud computing: all you need to know</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></description>
										<content:encoded><![CDATA[<span id="more-7424"></span>
<!--noteaser-->



<p>20 years ago we walked around with floppy disks. 15 years ago USB drives were thought the best way to transfer data between computers fast — but then Amazon launched AWS, its public cloud computing platform and the world has changed forever. Nowadays, everyone from freelancers to startups and global enterprises uses various cloud computing types to obtain, process and store all kinds of data and run their applications to generate revenues.</p>



<p>A forecast from IDC (International Data Corporation) promises worldwide spending on cloud services to reach $280 billion in 2021 and continue to grow at CAGR of 22%. However, while many companies have already adopted the cloud-first approach to their operations, many businesses are still unsure how to select the most suitable amidst different cloud computing types. This article will explore all you need to know about cloud computing types at a glance and will list business benefits to obtain from moving your IT operations to the cloud.</p>



<h2><b>What is cloud com</b>p<b>uting?</b></h2>



<p>What is cloud computing, in simple words? It is an approach to hardware utilization when all the computing resources owned by any cloud service provider are virtualized, pooled together and made available to users on demand. Every customer can scale their cloud instances up and down with ease to meet their workload challenges while paying only for the resources consumed (PAYG billing model), thus making the cloud much more cost-efficient, as compared to renting dedicated servers. Multiple cloud computing benefits like on-demand availability, simple scalability, high security and cost-efficiency of all IT operations are the factors that contribute to the growing adoption of the cloud by businesses around the globe.</p>



<p>Let’s just outline the infrastructure of a large corporation. Let’s say they have a data storage server that has to store all their financial records. If it was a single server, the enterprise risks losing all the data when its hard disk goes out of order. Therefore, at least a single replica is needed. But in order to ensure all the data is safely copied to both servers, you need a load balancer —&nbsp; a virtual machine on a third server, or just a third server.</p>



<p>Thus said, you need to maintain 3 servers and replace their faulty components st some time. You also have to pay for humidity control, cooling and fire control equipment, as well as have a secondary power supply on standby. Besides, the servers are hardly ever working at 100% of their capacity, so you always overpay for the resources you actually never used. Therefore, by combining CAPEX for purchasing hardware, software and supplementary systems with OPEX of paying for the maintenance and paying wages to IT specialists, you can see why the IT department is the cost center of expenses or any enterprise that wants to run its operations on-prem.</p>



<p>What is even worse, all these servers must be configured manually and separately. This always leads to a mess that should just be left alone, as restructuring it is literally impossible.</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="752" height="395" src="https://itsvit.com/wp-content/uploads/2020/03/Itsvit_Types-of-cloud_screen_2.png" alt="" class="wp-image-7425"/></figure>



<p>Enterprises were trying to solve this challenge in several ways to meet their demands by sharing their physical computing resources.&nbsp;</p>



<ul><li>Cluster computing — combining all the computers in a LAN into a single cluster. This allowed solving the tasks to resource-intensive for a single server, but reduced the performance of all the machines within the cluster, as their productivity was limited by the LAN throughput capacity.</li><li>Grid computing — combining the geographically distributed clusters to further increase the system computational power.</li><li>Distributed computing — connecting multiple devices in a ubiquitous landscape to provide peer-to-peer&nbsp; IT operations. ATM networks and Intranets/workgroups are good examples of such infrastructure.</li><li>Utility computing — providing disk storage, computing and various applications for a small fee, by virtualizing the resources of several servers. This concept grew into cloud computing as we know it today.</li></ul>



<p>Nowadays, large corporations and small startups alike use cloud computing to support their daily IT operations. It is useful for every industry — from small fintech startups to global manufacturing and retail giants, insurance and banking, real estate and telecom, software development and IT services.</p>



<h2>Basics of cloud computing operations</h2>



<p>As we briefly mentioned before, the main principle and killing feature of cloud computing is the fact that the resources provided to customers are elastic and can be scaled up and down independently in no time. With conventional dedicated servers, you have to buy or rent them in a remote data center in a pre-configured configuration.&nbsp;</p>



<p>First of all, if you don’t use all the server resources — you still pay in full. Secondly, if you ever need to increase the resources available, you need to buy another server — and double your expenses as hardware has quite limited horizontal scalability. Thirdly, but quite importantly, keeping an eye on your system parts and replacing the faulty components is your responsibility entirely, not to mention each adjustment is done manually and takes some time</p>



<p>Everything is different with the cloud. Your apps and data are still run on the same Linux (or Windows) server, but the way they are organized is totally changed. Computing resources of all the servers in all the racks in all the data centers are united into a common pool through virtualization. Every user pays for his/her <em>instance</em> — some quantity of computing resources assigned to them.&nbsp;</p>



<p>If the project requirements change and you need more resources — these can be added in a single click in your cloud computing dashboard — both vertically (adding more preconfigured instances) and horizontally (adding more RAM or CPU power or disk storage space independently). Shutting down these resources also takes a single click only.&nbsp;</p>



<p>This process can be repeated as many times as you need with literally no effort wasted.&nbsp; Most importantly, new instances are provisioned automatically — and you never overpay for idle resources, not to mention there is no need to pay for additional equipment or server hardware maintenance. Cloud data centers purchase server hardware in droves, so they simply rep</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="752" height="394" src="https://itsvit.com/wp-content/uploads/2020/03/Itsvit_Types-of-cloud_5-key-benefits_3.png" alt="" class="wp-image-7427"/></figure>



<h2>5 key benefits of cloud computing</h2>



<p>You can name all kinds of cloud computing benefits, based on your business niche and modus operandi. Here is our top 5 pick:&nbsp;</p>



<ol><li><b>Scalability </b>— scale your systems up and down on-demand and with ease.</li><li><b>High availability </b>— instead of accessing a single server over the Internet, modern customers access your services via a variety of apps across a wide range of resources — and cloud powers every interaction.</li><li><b>Shorter time-to-market</b> — due to an ability to provide the required environments nearly instantly, the cloud empowers your IT team to greatly reduce the time needed for developing new product features or services, and shorter time-to-market means great competitiveness.</li></ol>



<ol><li><b>Better cost-efficiency</b> — you save a lot on CAPEX and get value faster out of your cloud computing investments, but OPEX can be huge in case of misconfiguration. However, due to the PAYG model, you pay only for the resources consumed.</li><li><b>Security </b>— MS Azure, serves 95% of the Fortune1000 companies — global leaders in their industries. AWS stores and processes the data for the US DoD and CIA. Rest assured, cloud security is top-notch, and all the latest advancements in that field are first delivered to cloud platforms.</li></ol>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="752" height="394" src="https://itsvit.com/wp-content/uploads/2020/03/Itsvit_Types-of-cloud_3-different-types_4.png" alt="" class="wp-image-7429"/></figure>



<h2>3 different types of cloud computing&nbsp;</h2>



<p>There are three main types of cloud computing: providing Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS) or Software-as-a-Service (SaaS). Let’s take a closer look at these different cloud computing types and explain what is the best use for each of them.</p>



<h3>What is Infrastructure as a Service or IaaS</h3>



<p>Your system engineers know better how to build a cloud environment to meet your project requirements. All they need for this are building blocks — and this is exactly what IaaS is all about. Cloud service providers like AWS, Google Cloud, Microsoft Azure, IBM Cloud, Rackspace and others give DevOps specialists and system engineers access to the core of their platforms, so they can configure storage, networking, servers, security, deploy Terraform and Kubernetes and configure everything the way they need it, within the limits of their cloud account. But tread with caution, as errors can be quite costly with IaaS.</p>



<p>Back in the days, when AWS was a novelty that was actively growing and developing new features, one enterprise moved there from legacy infrastructure and enjoyed the scalability of the cloud. However, there was a minor bug in their operations — a data processing job was queued for execution, but never reporting successful completion. They thought it was caused by concurrency settings, so they just removed the limit on the number of jobs allowed to run at the same time.</p>



<p>In fact, the job was running, but failing due to incorrect process configuration. Once the limit on the concurrent jobs was removed, the system started spanning EMR clusters to perform the job and did it till it exhausted all the resources of us-east-1 Availability Zone. This resulted in an invoice for several million dollars awaiting the company in the morning. This case served as a basis for developing an internal AWS cloud monitoring solution, which later became AWS CloudWatch.</p>



<p>As you can see, IaaS is the most powerful — and the most error-prone of the cloud computing types.</p>



<h3>What is Platform-as-a-Service or PaaS&nbsp;</h3>



<p>PaaS is the next layer of the cloud computing pyramid. It means the cloud vendor provides various platforms as a service, which is very useful for developers. Due to PaaS, developers can use AWS CodeDeploy, CodePipeline and other tools, as well as Google App Engine or IBM Foundry to quickly develop their apps without ever having to configure the server.</p>



<p>Other PaaS tools include various cloud software, operating systems, middleware and all the environments required to support the software delivery lifecycle. These PaaS offers are accessed via the cloud vendor’s dashboard, are often activated and deactivated in a single click and allow hosting the required databases and data sets, BI tools and development solutions required on various stages of software development.</p>



<h3>What is Software-as-a-Service or SaaS</h3>



<p>SaaS is the uppermost level of the cloud pyramid. It includes IaaS and PaaS under the hood, but the customers cannot change anything apart from the settings of the software they consume. This is the level of applications like Office 360, Adobe products, Google G Suite, Salesforce and other cloud-native applications for businesses and individuals. You simply pay for receiving the functionality you need, but have no control over its installation, configuration or updates — all of this is done by the service provider.</p>



<figure class="wp-block-image size-large"><img loading="Lazy" loading="lazy" width="752" height="394" src="https://itsvit.com/wp-content/uploads/2020/03/Itsvit_Types-of-cloud_4-different-types_5.png" alt="" class="wp-image-7428"/></figure>



<h2>4 different cloud computing types</h2>



<p>There are 3 different cloud computing services types, distinguished by the level of customer control over the cloud resources he uses. These types are public, private and hybrid cloud, as well as multi-cloud strategy —&nbsp; and all of them have their benefits and shortcomings.</p>



<h3>Public cloud</h3>



<p>Public cloud means you share your resources with all other customers in that Availability Zone, just like using a public restroom. It is a cheap, efficient and reliable way to host your customer-facing applications. You get the zero CAPEX, on-demand scalability, high-availability and security of the cloud — but you do not have any SLA coverage. In addition, you have no control over where your sensitive data is processed — and there are stringent regulations that limit the businesses to storing the PII of the US citizens on US soil, for example. Thus said, private cloud cand be the solution in this case.</p>



<h3>Private cloud</h3>



<p>The private cloud is a sector of public cloud dedicated to serving a single customer. This way you can ensure your sensitive data physically resides within the US boundaries if your regulatory legislation demands it. Thus said, you retain full control over the configuration of software and networking resources, while the provider is still responsible for hardware maintenance and utility bills. Alternatively, private cloud solutions can be built in on-prem data centers, which is the preferred approach of global banking and financial institutions, as well as scientific and governmental institutions. In that case, you need to use tools like OpenShift and OpenStack to build and manage your private cloud system.</p>



<h3>Hybrid Cloud</h3>



<p>Hybrid cloud is a combination of public and private cloud, where an organization uses the unlimited resources of public cloud to process intense workloads while keeping all mission-critical data and systems running in the security of their private cloud. This is quite a popular approach for global corporations, who ensure both cost-efficiency and security of their IT operations with hybrid clouds.</p>



<h3>Multi-cloud strategy</h3>



<p>Nobody said you cannot use Amazon web services in tandem with Google Cloud platform — and so many companies do it. They build complex modular systems that include components from multiple cloud vendors and can sometimes even replace such modules with relative ease. This is a popular approach for global corporations, who have to run their workloads in regions not covered by any single cloud platform, so they have to combine services from several vendors.</p>



<h2>How to choose a reliable cloud computing provider</h2>



<p>Before selecting a cloud platform to deploy to, it is prudent to assess the range of its services, the data center locations, the pricing model, the customer support plans and data recovery scenarios available — in other words, it is good to have an in-depth knowledge of different cloud computing services and products to select the best fit for your project requirements.&nbsp;</p>



<p>IT Svit has such expertise due to 5+ years of providing managed IT services for various cloud computing types and projects of varying scale. We are known as the leader of the IT outsourcing market in Ukraine and the leading Managed DevOps Services Provider worldwide. We would be glad to provide an end-to-end solution for your projects and help you reach your business objectives. Order your free consultation today!</p>The post <a href="https://itsvit.com/blog/types-of-cloud-computing-all-you-need-to-know/">Types of cloud computing: all you need to know</a> first appeared on <a href="https://itsvit.com">IT Svit</a>.]]></content:encoded>
					
					<wfw:commentRss>https://itsvit.com/blog/types-of-cloud-computing-all-you-need-to-know/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
